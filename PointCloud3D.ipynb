{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EugenioBugli/3DPointCloud/blob/main/PointCloud3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_0FERiAhMW8"
      },
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kBbL55fBHVY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a29f764-a845-4f20-e902-dabbc010f2da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q open3d\n",
        "!pip install -q torch_scatter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "su0uRyWQE_On",
        "outputId": "061a349f-dc80-48f0-d69d-25b707acb58f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PyTorch version: 2.5.1+cu121  Device: cpu\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import DatasetFolder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import measure\n",
        "import tqdm\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_scatter import scatter_mean, scatter_max\n",
        "\n",
        "import open3d as o3d\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', device)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "drive_path = \"/content/drive/MyDrive/CV/MPI-FAUST\"\n",
        "training_path = drive_path + \"/training\"\n",
        "test_path = drive_path + \"/test\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLING_TYPE = \"RANDOM\"\n",
        "SAMPLING_SIZE = 1024*2\n",
        "BATCH_SIZE = 5\n",
        "\n",
        "IN_DIM_RES_PT = 64\n",
        "FEATURES_DIM = 32\n",
        "NUM_BLOCKS = 5\n",
        "NUM_FC = 4\n",
        "NUM_PLANES = 4\n",
        "NUM_COORDINATES = 3"
      ],
      "metadata": {
        "id": "pJUMCQszcoPr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFBi0FgT9WKe"
      },
      "source": [
        "# 1] Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FAUST_Dataset(Dataset):\n",
        "    \"\"\"\n",
        "        This class is used to load a partition of the FAUST dataset. Before using this you must access the file via DatasetFolder.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, scan_files, reg_files=None, sampling_type=\"RANDOM\", sampling_size=1024, partition=\"TRAIN\", transform=None):\n",
        "        super(FAUST_Dataset, self).__init__()\n",
        "        self.scan_files = scan_files # list of files .ply\n",
        "        self.partition = partition\n",
        "        self.reg_files = reg_files if partition in [\"TRAIN\", \"VAL\"] else None # list of files .ply\n",
        "        self.sampling_type = sampling_type\n",
        "        self.sampling_size = sampling_size\n",
        "        self.transform = transform\n",
        "\n",
        "        self.scans, self.regs = self.extractClouds()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.partition in [\"TRAIN\", \"VAL\"]:\n",
        "            if self.transform:\n",
        "                return self.transform(self.scans[index]).to(torch.float32).squeeze(0), self.transform(self.regs[index]).to(torch.float32).squeeze(0)\n",
        "            return self.scans[index], self.regs[index]\n",
        "        else: # test case\n",
        "            if self.transform:\n",
        "                return self.transform(self.scans[index]).to(torch.float32).squeeze(0)\n",
        "            return self.scans[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.scan_files)\n",
        "\n",
        "    def extractClouds(self):\n",
        "        # we have to open the files .ply and transform them into point clouds:\n",
        "\n",
        "        scans = []\n",
        "        regs = []\n",
        "\n",
        "        for i in range(len(self.scan_files)):\n",
        "            s = o3d.io.read_point_cloud(self.scan_files[i])\n",
        "            scans.append(self.SamplingFunction(s))\n",
        "\n",
        "            if self.partition in [\"TRAIN\", \"VAL\"]:\n",
        "                r = np.asarray(o3d.io.read_point_cloud(self.reg_files[i]).points)\n",
        "                regs.append(r)\n",
        "\n",
        "        return scans, regs if regs else None\n",
        "\n",
        "    def plotCloud(self, cloud):\n",
        "        \"\"\"\n",
        "        This function is used to plot the Point Cloud\n",
        "\n",
        "        Args:\n",
        "            cloud (np.array): Point Cloud\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        if len(cloud.shape) == 3:\n",
        "            # when using DataLoader you have a shape (1, SAMPLING_SIZE, 3)\n",
        "            cloud = cloud[0]\n",
        "\n",
        "        fig = go.Figure(\n",
        "            data=[\n",
        "            go.Scatter3d(\n",
        "                x =cloud[:,0], y=cloud[:,1], z=cloud[:,2],\n",
        "                mode = 'markers',\n",
        "                marker = dict(size=0.5, color=[])\n",
        "            )\n",
        "        ],\n",
        "        layout=dict(\n",
        "            scene=dict(\n",
        "                xaxis=dict(visible=True),\n",
        "                yaxis=dict(visible=True),\n",
        "                zaxis=dict(visible=True),\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        fig.show()\n",
        "\n",
        "    def SamplingFunction(self, cloud):\n",
        "        \"\"\"\n",
        "            This function is used to sample a small Subset of points from the Point Clouds inside our Dataset.\n",
        "\n",
        "            @INPUT :\n",
        "                > cloud : Point Cloud extracted from .ply file\n",
        "\n",
        "            @OUTPUT :\n",
        "                > sampled_cloud : Sampled Point Cloud\n",
        "        \"\"\"\n",
        "\n",
        "        if self.sampling_type == 'RANDOM':\n",
        "            points = np.asarray(cloud.points)\n",
        "            indices = np.random.choice(len(points), size=self.sampling_size)\n",
        "            sampled_cloud = points[indices]\n",
        "        if self.sampling_type == 'IMPORTANCE':\n",
        "            numOfNeighbors = 20\n",
        "            # estimate normal vectors to the surface at each point of the cloud\n",
        "            cloud.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamKNN(knn=numOfNeighbors))\n",
        "            tree = o3d.geometry.KDTreeFlann(cloud) # faster\n",
        "            # loop over the points and compute curvature\n",
        "            curvature = np.zeros(len(cloud.points))\n",
        "            for i in range(len(cloud.points)):\n",
        "                # find indices of the neighbors\n",
        "                [_ , idx, _] = tree.search_knn_vector_3d(cloud.points[i], numOfNeighbors)\n",
        "                neighbors = np.asarray(cloud.points)[idx, :]\n",
        "                # compute covariance matrix for each point\n",
        "                covarianceMat = np.cov(neighbors.T)\n",
        "                # extract eigenvalues\n",
        "                eigen, _ = np.linalg.eigh(covarianceMat)\n",
        "                # compute curvature\n",
        "                curvature[i] = min(eigen) / sum(eigen)\n",
        "            # extract the best SamplingPoints points\n",
        "            maxCurvaturePoints = curvature.argsort()[-self.SamplingSize:]\n",
        "            sampled_cloud = np.asarray(cloud.points)[maxCurvaturePoints]\n",
        "\n",
        "        return sampled_cloud\n",
        "\n",
        "# Save your preprocessed Dataset:\n",
        "def SaveDataset(dataset, path):\n",
        "    torch.save(dataset, \"/content/drive/MyDrive/CV/PreProcessed/\"+path)\n",
        "\n",
        "# Load your preprocessed Dataset:\n",
        "def LoadDataset(path):\n",
        "    return torch.load(\"/content/drive/MyDrive/CV/PreProcessed/\"+path, weights_only=False)\n"
      ],
      "metadata": {
        "id": "FGGKh1O7HuG1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use this to directly import the already pre-processed dataset\n",
        "\n",
        "train_set = LoadDataset(\"train_set.pt\")\n",
        "val_set = LoadDataset(\"val_set.pt\")\n",
        "test_set = LoadDataset(\"test_set.pt\")\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_set, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "2UANsdbf_on3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1] Pre-Processing"
      ],
      "metadata": {
        "id": "4gQKfOhn_YvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def openDataFiles(training_path, test_path, val_size):\n",
        "    \"\"\"\n",
        "        This function is used to import all the .ply files from the folders. Training is partitioned into train and validation set directly here.\n",
        "    \"\"\"\n",
        "\n",
        "    training_dataset = DatasetFolder(\n",
        "        root = training_path,\n",
        "        loader = o3d.io.read_point_cloud,\n",
        "        extensions = ('ply',),\n",
        "        allow_empty = True,\n",
        "        )\n",
        "\n",
        "    test_dataset = DatasetFolder(\n",
        "        root = test_path,\n",
        "        loader = o3d.io.read_point_cloud,\n",
        "        extensions = ('ply',),\n",
        "        allow_empty = True,\n",
        "    )\n",
        "\n",
        "    unsorted_training_scan_files = [sample for sample, t in training_dataset.samples if t == 2]\n",
        "    training_scan_files = sorted(unsorted_training_scan_files, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
        "\n",
        "    unsorted_training_reg_files = [sample for sample, t in training_dataset.samples if t == 1]\n",
        "    training_reg_files = sorted(unsorted_training_reg_files, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
        "\n",
        "    # perform train-validation split :\n",
        "\n",
        "    train_scan_files, val_scan_files, train_reg_files, val_reg_files = train_test_split(training_scan_files, training_reg_files, test_size=val_size, random_state=15)\n",
        "\n",
        "\n",
        "    unsorted_test_scan_files = [sample for sample, t in test_dataset.samples if t == 1]\n",
        "    test_scan_files = sorted(unsorted_test_scan_files, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
        "    test_reg_files = test_scan_files # check here\n",
        "    # we don't have any registration for the test set --> use instead the complete point cloud\n",
        "\n",
        "\n",
        "    return train_scan_files, train_reg_files, val_scan_files, val_reg_files, test_scan_files, test_reg_files\n"
      ],
      "metadata": {
        "id": "gqccCCSfJA0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import all the files from folders + perform the split\n",
        "train_scan_files, train_reg_files, val_scan_files, val_reg_files, test_scan_files, test_reg_files = openDataFiles(training_path, test_path, val_size=0.2)\n",
        "\n",
        "train_set = FAUST_Dataset(train_scan_files, train_reg_files, sampling_type=SAMPLING_TYPE, sampling_size=SAMPLING_SIZE, partition=\"TRAIN\", transform=transforms.ToTensor())\n",
        "val_set = FAUST_Dataset(val_scan_files, val_reg_files, sampling_type=SAMPLING_TYPE, sampling_size=SAMPLING_SIZE, partition=\"VAL\", transform=transforms.ToTensor())\n",
        "test_set = FAUST_Dataset(test_scan_files, test_reg_files, sampling_type=SAMPLING_TYPE, sampling_size=SAMPLING_SIZE, partition=\"TEST\", transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_set, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "tLW7oe-KLhms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2] Visualization"
      ],
      "metadata": {
        "id": "FC0Pc51bA4sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from matplotlib\n",
        "for batch in train_loader:\n",
        "    eg = batch[0][0]\n",
        "    eg = (eg - eg.min())/(eg.max() - eg.min() + 10e-6)\n",
        "\n",
        "    figure3D = plt.figure(figsize=(7,7))\n",
        "    axes3D = plt.axes(projection='3d')\n",
        "    axes3D.scatter(eg[:, 0], eg[:, 1], eg[:, 2], alpha=0.5)\n",
        "\n",
        "    # project this points in 2D\n",
        "\n",
        "    figure2D = plt.figure(figsize=(7,7))\n",
        "    axes2D = plt.axes()\n",
        "    axes2D.scatter(eg[:, 0], eg[:, 1], alpha=0.5)\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "SbddXMKdA-dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def voxel2Numpy(voxel):\n",
        "    voxels = voxel.get_voxels()\n",
        "    # notice that the coordinates are in the voxel grid !\n",
        "    indices = np.stack(list(vx.grid_index for vx in voxels))\n",
        "    return indices"
      ],
      "metadata": {
        "id": "HW1YAZuhWDI6"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exploit open3d\n",
        "for batch in train_loader:\n",
        "    eg = batch[0][0]\n",
        "    eg = (eg - eg.min())/(eg.max() - eg.min() + 10e-6)\n",
        "    pc = o3d.geometry.PointCloud()\n",
        "    pc.points = o3d.utility.Vector3dVector(eg)\n",
        "    print(pc)\n",
        "    o3d.visualization.draw_plotly([pc])\n",
        "\n",
        "    pc.scale(1 / np.max(pc.get_max_bound() - pc.get_min_bound()), center=pc.get_center())\n",
        "\n",
        "    # try downsampling the point cloud that you have with 3D voxels\n",
        "\n",
        "    voxel = o3d.geometry.VoxelGrid.create_from_point_cloud(pc, voxel_size=0.9)\n",
        "    vec3d = o3d.utility.Vector3dVector(eg)\n",
        "    # use this to check if your points are inside the voxel\n",
        "    print(np.asarray(voxel.check_if_included(vec3d)))\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "D6NzdqrqP5mj",
        "outputId": "6442a514-ea99-4538-fcbd-0e7f74c1de0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PointCloud with 2048 points.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a4241662-8b5b-458c-b959-3b49af5a1ff0\" class=\"plotly-graph-div\" style=\"height:400px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a4241662-8b5b-458c-b959-3b49af5a1ff0\")) {                    Plotly.newPlot(                        \"a4241662-8b5b-458c-b959-3b49af5a1ff0\",                        [{\"marker\":{\"color\":[[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0],[1.0,0.0,0.0]],\"size\":1},\"mode\":\"markers\",\"x\":[0.5789774656295776,0.6139174103736877,0.4993417263031006,0.496390163898468,0.5799551010131836,0.5394614934921265,0.6339992880821228,0.5331156253814697,0.6797970533370972,0.664385974407196,0.505652904510498,0.47745421528816223,0.6759281754493713,0.5491042137145996,0.6380482316017151,0.5993407964706421,0.5730852484703064,0.5690332055091858,0.6733599305152893,0.4348967373371124,0.7275667190551758,0.49263206124305725,0.6100045442581177,0.6144176125526428,0.5934521555900574,0.6731024980545044,0.6484065651893616,0.6029115319252014,0.5671250224113464,0.6629095077514648,0.5015432834625244,0.34196242690086365,0.6689165830612183,0.6593819260597229,0.6745041608810425,0.5256348848342896,0.5295721888542175,0.5182957053184509,0.5548990964889526,0.5205727219581604,0.4013410210609436,0.4399780035018921,0.6549484133720398,0.6001536846160889,0.6760011911392212,0.6075933575630188,0.5977967381477356,0.4779259264469147,0.6648607850074768,0.32232382893562317,0.4880478084087372,0.6193447709083557,0.5436000823974609,0.5670304894447327,0.512316107749939,0.5341971516609192,0.3331688642501831,0.4617074131965637,0.7645264863967896,0.5247498750686646,0.5095935463905334,0.46386995911598206,0.6736041307449341,0.5063786506652832,0.6701407432556152,0.3521946966648102,0.47284743189811707,0.5894070863723755,0.6344254016876221,0.5460818409919739,0.4549362361431122,0.5596522092819214,0.5241873264312744,0.515996515750885,0.47767874598503113,0.501785397529602,0.46479955315589905,0.7728792428970337,0.5332850813865662,0.6192330121994019,0.5980284810066223,0.5673837065696716,0.6538642644882202,0.6253950595855713,0.5546287298202515,0.5531360507011414,0.6182032227516174,0.4848783612251282,0.604300320148468,0.5210337042808533,0.6725193858146667,0.6699756383895874,0.5070666670799255,0.5260136127471924,0.534207820892334,0.589753270149231,0.6701148152351379,0.6793956756591797,0.7150408625602722,0.6127830147743225,0.541106104850769,0.6120777130126953,0.5137710571289062,0.5066057443618774,0.47083455324172974,0.5992011427879333,0.5031160712242126,0.5724087953567505,0.5386809706687927,0.5069777965545654,0.5024018883705139,0.6492967009544373,0.5906668305397034,0.6510570049285889,0.6880316138267517,0.5802507400512695,0.6009507775306702,0.4620230793952942,0.6228878498077393,0.6725944876670837,0.552426815032959,0.6561784148216248,0.5514751076698303,0.523337185382843,0.5392767786979675,0.6105999946594238,0.7006358504295349,0.5295271873474121,0.7943218350410461,0.7305641174316406,0.6273887157440186,0.528330385684967,0.5970274806022644,0.5298974514007568,0.5970681309700012,0.7264204621315002,0.7687474489212036,0.5307432413101196,0.6300014853477478,0.4295188784599304,0.6421312689781189,0.530937671661377,0.516620934009552,0.7549379467964172,0.6779995560646057,0.5861465930938721,0.5059473514556885,0.5177338123321533,0.5913107991218567,0.603816032409668,0.5059381127357483,0.47980862855911255,0.6266246438026428,0.5562283396720886,0.6158850789070129,0.5383378863334656,0.6628751754760742,0.5175433158874512,0.34337085485458374,0.6684320569038391,0.5386825203895569,0.49443018436431885,0.5146239399909973,0.4634280204772949,0.47052183747291565,0.6353135108947754,0.6119805574417114,0.3655238747596741,0.5943897366523743,0.6672630310058594,0.47594761848449707,0.527238667011261,0.5107869505882263,0.658367931842804,0.5023046731948853,0.7063527703285217,0.5895556807518005,0.6443588733673096,0.4735860824584961,0.5230936408042908,0.6105286478996277,0.5022544264793396,0.6789660453796387,0.5785654783248901,0.5275826454162598,0.534407913684845,0.6515498161315918,0.64455646276474,0.3736857771873474,0.7485501766204834,0.6301460862159729,0.7194228768348694,0.7820169925689697,0.5823681950569153,0.601162314414978,0.7232504487037659,0.7189420461654663,0.5706705451011658,0.6439864039421082,0.563661515712738,0.5130625367164612,0.6899126768112183,0.5279301404953003,0.6452699303627014,0.5901382565498352,0.7483475208282471,0.5098662972450256,0.5304183959960938,0.5345063209533691,0.5790913105010986,0.5525553822517395,0.4154379665851593,0.5297629833221436,0.5269852876663208,0.6577878594398499,0.3825374245643616,0.548245370388031,0.47319161891937256,0.5149110555648804,0.6084108948707581,0.33953848481178284,0.46478649973869324,0.37369316816329956,0.6508058309555054,0.6026535630226135,0.6948291659355164,0.6152061223983765,0.5932027101516724,0.49203693866729736,0.5743773579597473,0.6208633184432983,0.7987410426139832,0.5792100429534912,0.612110435962677,0.49523210525512695,0.4743926227092743,0.674675703048706,0.6489762663841248,0.7617374062538147,0.5384465456008911,0.5549902319908142,0.6717857122421265,0.5341306924819946,0.622296929359436,0.7158365845680237,0.6061298847198486,0.639230489730835,0.5592129230499268,0.5244497060775757,0.5137955546379089,0.5132669806480408,0.5355754494667053,0.48967626690864563,0.6865831017494202,0.6832802891731262,0.5690796375274658,0.6038722395896912,0.5288857817649841,0.6517571806907654,0.6755051612854004,0.5553537607192993,0.49673962593078613,0.5320653319358826,0.6345524787902832,0.4630502462387085,0.6036882400512695,0.5261180996894836,0.6066190004348755,0.7158559560775757,0.5058801770210266,0.623638391494751,0.6323020458221436,0.49822723865509033,0.7452207803726196,0.7320417761802673,0.7297836542129517,0.6147261261940002,0.5773261189460754,0.5568224191665649,0.548882007598877,0.6599462628364563,0.49244675040245056,0.50202476978302,0.6472838521003723,0.8063662648200989,0.6173464059829712,0.6191264390945435,0.5159003138542175,0.4735065698623657,0.6272944211959839,0.5109723806381226,0.5150414705276489,0.5074339509010315,0.6525737643241882,0.5177514553070068,0.520662248134613,0.5346670150756836,0.47812822461128235,0.6139057278633118,0.6553350687026978,0.5113714337348938,0.5985161066055298,0.5612389445304871,0.5118526816368103,0.5495976209640503,0.664354681968689,0.5006054639816284,0.7639041543006897,0.5156903266906738,0.6765138506889343,0.6326141357421875,0.7081540822982788,0.6675266623497009,0.628176748752594,0.5390693545341492,0.5850053429603577,0.5358677506446838,0.5274075269699097,0.5088500380516052,0.541775643825531,0.6575603485107422,0.5951510071754456,0.47434595227241516,0.4855150580406189,0.48955652117729187,0.6973543167114258,0.5382692813873291,0.5103226900100708,0.6327152252197266,0.526050329208374,0.6702054738998413,0.4728997051715851,0.5175840258598328,0.5210614204406738,0.6062641739845276,0.5603658556938171,0.6464649438858032,0.3619149327278137,0.598196268081665,0.6096386313438416,0.5766220092773438,0.6163586378097534,0.5401869416236877,0.5429638624191284,0.6507927179336548,0.7059909105300903,0.5899307727813721,0.6822559833526611,0.5357223153114319,0.6148239374160767,0.6020811796188354,0.7119541764259338,0.46343135833740234,0.37964025139808655,0.6571866869926453,0.6590194702148438,0.6476872563362122,0.7710828185081482,0.6424316167831421,0.5469287633895874,0.702817440032959,0.6744571328163147,0.5858049392700195,0.331635445356369,0.5167933702468872,0.7373772263526917,0.5953942537307739,0.673768937587738,0.6775158047676086,0.7987410426139832,0.47888582944869995,0.627187192440033,0.40756532549858093,0.48503240942955017,0.5402098894119263,0.5026164054870605,0.6408098936080933,0.584585428237915,0.6193598508834839,0.5558480620384216,0.6823629140853882,0.5654373168945312,0.6210373044013977,0.5794150233268738,0.4595164656639099,0.5999401211738586,0.5687318444252014,0.6167316436767578,0.34836313128471375,0.6117839217185974,0.659539520740509,0.47516876459121704,0.7188363671302795,0.6352975368499756,0.5089113712310791,0.5284328460693359,0.4910471737384796,0.6093903183937073,0.38650327920913696,0.6381023526191711,0.5054216980934143,0.6210616827011108,0.5524418354034424,0.3366301357746124,0.5206703543663025,0.6076350808143616,0.7721548080444336,0.6170276999473572,0.6395796537399292,0.635250985622406,0.6238695383071899,0.5130213499069214,0.5163667798042297,0.49852094054222107,0.5903100967407227,0.5579752922058105,0.5826559662818909,0.46151003241539,0.542165994644165,0.6264942288398743,0.5925183296203613,0.7088663578033447,0.45239707827568054,0.6797065138816833,0.4595150947570801,0.6371026039123535,0.7101356387138367,0.6333218216896057,0.6574345231056213,0.33269092440605164,0.6718865633010864,0.6142409443855286,0.6366768479347229,0.6788823008537292,0.501006007194519,0.5942740440368652,0.6118730306625366,0.5177657008171082,0.5145647525787354,0.7338784337043762,0.5017688274383545,0.6869802474975586,0.49429869651794434,0.5436134934425354,0.6608120203018188,0.5309855341911316,0.6835185289382935,0.5068078637123108,0.3367520272731781,0.46225476264953613,0.7808833122253418,0.6814813613891602,0.5337929129600525,0.5452859997749329,0.6825826168060303,0.5008947253227234,0.5985110402107239,0.6655253171920776,0.4816448986530304,0.6747062802314758,0.6499952673912048,0.62699955701828,0.5556499361991882,0.5350366234779358,0.6214509606361389,0.504840075969696,0.656840443611145,0.6820300221443176,0.6516078114509583,0.4563487470149994,0.6019272208213806,0.46753165125846863,0.5438295006752014,0.7612074613571167,0.49123767018318176,0.6152821779251099,0.6700200438499451,0.6095679402351379,0.6692294478416443,0.592272162437439,0.5143933296203613,0.645997166633606,0.6570165753364563,0.6479099988937378,0.549816906452179,0.7259328961372375,0.5536753535270691,0.5439791083335876,0.5925517082214355,0.5033301115036011,0.49311745166778564,0.5515802502632141,0.8057772517204285,0.5608404874801636,0.4673738479614258,0.5182524919509888,0.43416357040405273,0.6225268840789795,0.5558934211730957,0.7682777643203735,0.667610764503479,0.5204886794090271,0.5058901906013489,0.5780504941940308,0.7268946170806885,0.4753594398498535,0.6427397727966309,0.6506916284561157,0.6776291728019714,0.5088472366333008,0.5820055603981018,0.5479351282119751,0.5602179765701294,0.5973747372627258,0.5908176898956299,0.5421770215034485,0.5369291305541992,0.6182427406311035,0.39729949831962585,0.5811804533004761,0.6766213774681091,0.6788747310638428,0.5187934637069702,0.4059080183506012,0.6452412009239197,0.4695882499217987,0.6409246325492859,0.6677334308624268,0.4984497129917145,0.5240840911865234,0.46810781955718994,0.5337371826171875,0.6597226858139038,0.5715753436088562,0.6723207831382751,0.5435259342193604,0.5489436984062195,0.7299604415893555,0.5890063047409058,0.37627744674682617,0.6474656462669373,0.6262925267219543,0.4731912910938263,0.6124052405357361,0.5783703923225403,0.6624054908752441,0.6502344012260437,0.5616472959518433,0.5156359672546387,0.4726608097553253,0.6604428291320801,0.526716411113739,0.5076645612716675,0.6131237745285034,0.5236202478408813,0.7274672985076904,0.6861186623573303,0.5856980085372925,0.5132597088813782,0.5100395083427429,0.5122956037521362,0.5292661786079407,0.6759639978408813,0.6686068177223206,0.527572512626648,0.6751516461372375,0.6861912608146667,0.5565071702003479,0.5806563496589661,0.568737268447876,0.46509578824043274,0.479522168636322,0.6392688155174255,0.60969078540802,0.44242992997169495,0.5548163652420044,0.5166966319084167,0.7232669591903687,0.6224638819694519,0.7267175316810608,0.5836219787597656,0.4708559215068817,0.6321264505386353,0.5991273522377014,0.6784346699714661,0.43755900859832764,0.7257968783378601,0.6831493973731995,0.5299651622772217,0.5074721574783325,0.48827847838401794,0.4631164073944092,0.5145213603973389,0.6662120819091797,0.5128023624420166,0.7184005379676819,0.5142444372177124,0.678041398525238,0.657954752445221,0.667140007019043,0.7233458757400513,0.783923327922821,0.47250524163246155,0.5334140062332153,0.7217715382575989,0.7169763445854187,0.5109277367591858,0.612343966960907,0.6120989918708801,0.47975242137908936,0.6613966226577759,0.6095077991485596,0.5847188830375671,0.5077877044677734,0.49701979756355286,0.4494697153568268,0.5894326567649841,0.4870609641075134,0.5986307859420776,0.46682775020599365,0.5178002715110779,0.5164250135421753,0.6495084762573242,0.6411771178245544,0.6477494239807129,0.48144999146461487,0.6370167136192322,0.760036289691925,0.4522320628166199,0.611116886138916,0.6791148781776428,0.5651966333389282,0.6441318392753601,0.5852403044700623,0.7280436158180237,0.3621833026409149,0.6709161996841431,0.48521509766578674,0.6049144864082336,0.6119192242622375,0.5168092846870422,0.5553537607192993,0.560789167881012,0.5830977559089661,0.5116426348686218,0.6151520609855652,0.8002784252166748,0.4596700668334961,0.5345227122306824,0.4776827394962311,0.619282603263855,0.6372016668319702,0.5738539099693298,0.5349501967430115,0.3922930955886841,0.680494487285614,0.5096204876899719,0.6423888206481934,0.49840396642684937,0.5077781081199646,0.6768055558204651,0.5962266325950623,0.6262955069541931,0.7149049639701843,0.4638407528400421,0.5935301184654236,0.5236003994941711,0.5257723927497864,0.5784600973129272,0.6605482697486877,0.6394544839859009,0.4781801402568817,0.7631148099899292,0.6772187352180481,0.6495848298072815,0.5230897665023804,0.7028355598449707,0.5362665057182312,0.5954296588897705,0.43576547503471375,0.7717236280441284,0.52906733751297,0.605653703212738,0.4820385277271271,0.6647106409072876,0.7825722098350525,0.6700096726417542,0.678227961063385,0.6447909474372864,0.6458516120910645,0.5856720805168152,0.5199424028396606,0.6872073411941528,0.4609997570514679,0.6621862053871155,0.5788630843162537,0.6048979759216309,0.5013192892074585,0.5916726589202881,0.46262040734291077,0.6459242105484009,0.5155193209648132,0.5834863185882568,0.6116814017295837,0.45107463002204895,0.6100130081176758,0.43236100673675537,0.6448039412498474,0.5391585230827332,0.6801552176475525,0.4347376525402069,0.6592490673065186,0.6787262558937073,0.7837243676185608,0.550537645816803,0.5962266325950623,0.5413709878921509,0.6779605150222778,0.4705384075641632,0.6749476790428162,0.6147379279136658,0.6075423955917358,0.5744286775588989,0.5183433890342712,0.5905300974845886,0.4919080138206482,0.7495847344398499,0.5966994166374207,0.45601677894592285,0.5176633596420288,0.3999088704586029,0.5276040434837341,0.7272639274597168,0.5342808961868286,0.46615153551101685,0.5222501158714294,0.407701700925827,0.5411139726638794,0.6002693176269531,0.6496289968490601,0.6341757774353027,0.5587025284767151,0.6334387063980103,0.6039420366287231,0.6662436127662659,0.6331269145011902,0.47760099172592163,0.473063200712204,0.5092452764511108,0.7617063522338867,0.5230582356452942,0.5252013206481934,0.5292826294898987,0.5751317739486694,0.7123313546180725,0.5043847560882568,0.5425329208374023,0.6468560099601746,0.5783765912055969,0.6160762310028076,0.4621027112007141,0.6430983543395996,0.5743996500968933,0.5456076264381409,0.5203493237495422,0.5581238269805908,0.5494462251663208,0.5801453590393066,0.5911625027656555,0.4637736678123474,0.6034380793571472,0.47955167293548584,0.5168343782424927,0.6417428255081177,0.6309106349945068,0.5495561361312866,0.5642107725143433,0.682914674282074,0.6361116170883179,0.6076642870903015,0.5015679597854614,0.7334668636322021,0.6579256057739258,0.670401394367218,0.6726531982421875,0.4851817786693573,0.6731692552566528,0.5875921845436096,0.6923881769180298,0.4648398458957672,0.5385434627532959,0.4586236774921417,0.5085977911949158,0.6780197024345398,0.6680248379707336,0.40416380763053894,0.6729637980461121,0.6675853133201599,0.6878336668014526,0.5685564279556274,0.5491153597831726,0.7179666757583618,0.7087663412094116,0.6356539726257324,0.7264420390129089,0.4756563901901245,0.7138890624046326,0.5939164161682129,0.522087812423706,0.5363913774490356,0.7261537313461304,0.6798321604728699,0.6553755402565002,0.5808647274971008,0.5601904988288879,0.6520354747772217,0.6687697768211365,0.3619149327278137,0.68379145860672,0.5724122524261475,0.5612483024597168,0.48255082964897156,0.6049304008483887,0.49417200684547424,0.6911114454269409,0.5987188816070557,0.5345603823661804,0.5125567317008972,0.7094035744667053,0.5962001085281372,0.5435721278190613,0.5738418698310852,0.49753573536872864,0.5483594536781311,0.5581360459327698,0.5343832969665527,0.7693366408348083,0.45874425768852234,0.6494457721710205,0.7724171280860901,0.5481073260307312,0.5949850082397461,0.5619645714759827,0.4555416405200958,0.46894827485084534,0.6482831239700317,0.5073842406272888,0.5415248870849609,0.6246129274368286,0.7298881411552429,0.5386648774147034,0.6806443333625793,0.5805960297584534,0.5552693009376526,0.6883562207221985,0.6799135208129883,0.5039352178573608,0.6414400935173035,0.5030568838119507,0.6406587362289429,0.6936450600624084,0.6320029497146606,0.4648599922657013,0.5267355442047119,0.6004341840744019,0.48201751708984375,0.4745870530605316,0.5610550045967102,0.5134906768798828,0.5799113512039185,0.6685112714767456,0.5541036128997803,0.6078444719314575,0.6429446339607239,0.4678592085838318,0.5346064567565918,0.6210430264472961,0.531474769115448,0.5147908329963684,0.7179567217826843,0.5100265741348267,0.6005991697311401,0.624889075756073,0.6871681809425354,0.6491761207580566,0.5944507122039795,0.6887301206588745,0.609719455242157,0.5075337290763855,0.550116240978241,0.6823940873146057,0.5614696145057678,0.608359158039093,0.5459312200546265,0.5145794153213501,0.4950600266456604,0.7593176960945129,0.4726475179195404,0.6749044060707092,0.6626139283180237,0.5541052222251892,0.5013948678970337,0.6083704233169556,0.5732354521751404,0.505468487739563,0.7449783086776733,0.5826554298400879,0.6258672475814819,0.7145096063613892,0.5072576999664307,0.6703324317932129,0.6629507541656494,0.8097761273384094,0.7226526141166687,0.6320093274116516,0.5168486833572388,0.6472429633140564,0.6362955570220947,0.6407783031463623,0.5486484169960022,0.5465875267982483,0.5579447150230408,0.7076781392097473,0.6772983074188232,0.5651594400405884,0.6369360685348511,0.5961163640022278,0.6046149134635925,0.5730447173118591,0.5224121809005737,0.7634205222129822,0.5814484357833862,0.6210156679153442,0.5820055603981018,0.7820453643798828,0.500041127204895,0.5806792378425598,0.6294831037521362,0.6097396612167358,0.6792050004005432,0.5541130900382996,0.6014624238014221,0.5538843870162964,0.4675288498401642,0.6138763427734375,0.469481885433197,0.6104019284248352,0.41743239760398865,0.5970576405525208,0.678918182849884,0.4943252503871918,0.6737218499183655,0.5385812520980835,0.6683529019355774,0.7253571152687073,0.5259509086608887,0.6453381776809692,0.46156904101371765,0.5306910872459412,0.5361536145210266,0.689773678779602,0.36957406997680664,0.6426560282707214,0.5737517476081848,0.606229305267334,0.6887742280960083,0.5308471322059631,0.5072166323661804,0.4779259264469147,0.6853592991828918,0.6512157320976257,0.4805934429168701,0.4774223864078522,0.5475484132766724,0.5071133375167847,0.5431009531021118,0.46806618571281433,0.6525670886039734,0.5880178809165955,0.621236264705658,0.641693651676178,0.6215957999229431,0.4511471688747406,0.7936509847640991,0.5529145002365112,0.6808820366859436,0.6019811034202576,0.6126976609230042,0.604786217212677,0.5326746106147766,0.46841588616371155,0.56927490234375,0.6575717926025391,0.6455824971199036,0.5997336506843567,0.5681449174880981,0.499562531709671,0.5091922879219055,0.6345351934432983,0.48659399151802063,0.4769619107246399,0.7257456183433533,0.5050156116485596,0.5405853986740112,0.632978618144989,0.4822992980480194,0.5385812520980835,0.49241989850997925,0.7042796015739441,0.5373896360397339,0.6480439305305481,0.5614809393882751,0.4549437165260315,0.7229418158531189,0.5720410346984863,0.5283833742141724,0.49818333983421326,0.5451842546463013,0.7064484357833862,0.6148409843444824,0.6088045239448547,0.5074869990348816,0.6727333068847656,0.6156407594680786,0.6047713756561279,0.6662486791610718,0.49020805954933167,0.6072032451629639,0.701834499835968,0.5087103247642517,0.5076795816421509,0.518032968044281,0.33632874488830566,0.6813408732414246,0.6813390851020813,0.6496982574462891,0.49235478043556213,0.6468333005905151,0.7126784324645996,0.5649304389953613,0.6155973076820374,0.6540828943252563,0.6161677837371826,0.596481442451477,0.590043842792511,0.6588640213012695,0.5719032287597656,0.5639715790748596,0.5291650295257568,0.46950826048851013,0.5306249856948853,0.5484155416488647,0.6801323294639587,0.6471313834190369,0.5400046706199646,0.5671475529670715,0.5546717047691345,0.6741262078285217,0.5221899747848511,0.6145617365837097,0.5010268688201904,0.644076406955719,0.4990231692790985,0.6787026524543762,0.5396147966384888,0.5131707191467285,0.507534921169281,0.6446054577827454,0.5514121055603027,0.6304481625556946,0.6279894709587097,0.46812769770622253,0.456605464220047,0.648013174533844,0.5021138787269592,0.6067163944244385,0.3410586416721344,0.5666663646697998,0.5456556677818298,0.6093211770057678,0.5576098561286926,0.5435085892677307,0.5316686034202576,0.5044320225715637,0.6403698325157166,0.5967630743980408,0.6299607753753662,0.4726579189300537,0.5186344385147095,0.7944315075874329,0.5316200852394104,0.5256090760231018,0.6515848636627197,0.6739746332168579,0.6645650267601013,0.5342282652854919,0.6752161383628845,0.761347770690918,0.44342267513275146,0.5055428147315979,0.5903063416481018,0.5345367789268494,0.5006133317947388,0.6405091285705566,0.6681289076805115,0.4722065329551697,0.6201382875442505,0.6483063101768494,0.5206480622291565,0.5297654867172241,0.4994209110736847,0.6313294172286987,0.4983690679073334,0.47676441073417664,0.6345599293708801,0.612596333026886,0.56708824634552,0.6792536377906799,0.6721152067184448,0.5696375966072083,0.5464180111885071,0.5177406668663025,0.5507640838623047,0.6208115816116333,0.6266196370124817,0.6142346262931824,0.48339706659317017,0.48147833347320557,0.6510443687438965,0.5958414077758789,0.5236162543296814,0.5184741020202637,0.7217312455177307,0.5185731053352356,0.727681040763855,0.7153158187866211,0.4366787374019623,0.4619997441768646,0.5513640642166138,0.6635470986366272,0.5148677825927734,0.597896158695221,0.7805398106575012,0.5329378843307495,0.6759874820709229,0.6745462417602539,0.45466846227645874,0.6336422562599182,0.5116270184516907,0.5575261116027832,0.684764564037323,0.5688725113868713,0.6573770642280579,0.6508471369743347,0.623613178730011,0.48229846358299255,0.5797715783119202,0.641851544380188,0.40648892521858215,0.5332989692687988,0.6442967653274536,0.5863256454467773,0.49879446625709534,0.7179480791091919,0.46674326062202454,0.6220760345458984,0.5631672739982605,0.5348618626594543,0.6212789416313171,0.6138731241226196,0.4846888482570648,0.5842514038085938,0.5286271572113037,0.35411491990089417,0.5385302901268005,0.5033321976661682,0.6413334012031555,0.6215246915817261,0.35791707038879395,0.5495550632476807,0.7077286243438721,0.6025393009185791,0.509672224521637,0.6510710120201111,0.497811496257782,0.6761807203292847,0.5383720397949219,0.5366401076316833,0.4910697340965271,0.6635375618934631,0.5518001317977905,0.6450979113578796,0.5946282744407654,0.7098888754844666,0.5081067085266113,0.48760518431663513,0.5072529315948486,0.5722886919975281,0.673613965511322,0.507118284702301,0.4717841148376465,0.6052793264389038,0.5181998014450073,0.5073817372322083,0.46979019045829773,0.6080541610717773,0.5593495965003967,0.6083395481109619,0.5070129036903381,0.6962751746177673,0.5323255062103271,0.732593834400177,0.36548876762390137,0.6647711992263794,0.6574797630310059,0.6014345288276672,0.5032275915145874,0.6404228806495667,0.5593174695968628,0.6615893840789795,0.5325177907943726,0.5024476647377014,0.6909060478210449,0.6152722239494324,0.5985767245292664,0.6765943765640259,0.5494005084037781,0.665887176990509,0.6693906188011169,0.602943480014801,0.5848547220230103,0.6059634685516357,0.3775383532047272,0.49434149265289307,0.6090697050094604,0.5463926792144775,0.5705482363700867,0.6105962991714478,0.6723940372467041,0.6208595633506775,0.618873655796051,0.47193998098373413,0.4804023206233978,0.6439775824546814,0.6659374237060547,0.6010213494300842,0.5949901342391968,0.4969227612018585,0.6442794799804688,0.6369442343711853,0.4759628176689148,0.5058068037033081,0.6231406331062317,0.668852686882019,0.7299433350563049,0.4873572587966919,0.4629261791706085,0.5797181129455566,0.8005774021148682,0.4811412990093231,0.6806235909461975,0.6264930963516235,0.6700841188430786,0.49579480290412903,0.4679454267024994,0.6313610076904297,0.6829559206962585,0.6786513924598694,0.4877084493637085,0.6699717044830322,0.5280230641365051,0.6000739336013794,0.5767237544059753,0.5418742895126343,0.693710446357727,0.49701839685440063,0.46330010890960693,0.6104867458343506,0.43572887778282166,0.5423829555511475,0.38009876012802124,0.7986747026443481,0.5945388078689575,0.49732840061187744,0.4726475179195404,0.6046844720840454,0.6927523016929626,0.7673572301864624,0.6184364557266235,0.740756094455719,0.5836713314056396,0.5189136266708374,0.7915504574775696,0.5244553685188293,0.660363495349884,0.6479609608650208,0.6482759714126587,0.5213587284088135,0.4836640954017639,0.7829174995422363,0.6742438673973083,0.5841349959373474,0.660219669342041,0.5933718681335449,0.5818967819213867,0.6403983235359192,0.47351089119911194,0.657828152179718,0.5739033222198486,0.4925350546836853,0.48497065901756287,0.5385326147079468,0.5905267596244812,0.45950618386268616,0.6255490183830261,0.6300176382064819,0.4639778137207031,0.5196545124053955,0.5223706960678101,0.6381237506866455,0.5662727952003479,0.5894849896430969,0.7887303829193115,0.713715672492981,0.5268547534942627,0.7415034770965576,0.47829800844192505,0.46140557527542114,0.6703721880912781,0.5488742589950562,0.7355493903160095,0.6362332701683044,0.47438928484916687,0.5132201313972473,0.6435394287109375,0.506226658821106,0.5903337001800537,0.5007508993148804,0.5141811370849609,0.5464175939559937,0.634996235370636,0.5535598993301392,0.6587131023406982,0.5519154667854309,0.48608168959617615,0.6050737500190735,0.702872633934021,0.46044886112213135,0.47890985012054443,0.641851544380188,0.5233460664749146,0.49940168857574463,0.6773321628570557,0.5968504548072815,0.5773077607154846,0.6219993829727173,0.49779820442199707,0.6129531860351562,0.6021677851676941,0.5202199220657349,0.6399070024490356,0.6417100429534912,0.6709272861480713,0.5192722082138062,0.5762367248535156,0.6440383791923523,0.6508978605270386,0.7887863516807556,0.5717979669570923,0.4458671808242798,0.5617058873176575,0.6169784069061279,0.4089258015155792,0.6228951811790466,0.6545886397361755,0.5967206358909607,0.5954319834709167,0.6740825772285461,0.35830482840538025,0.6378777027130127,0.6077671051025391,0.6286301612854004,0.6302584409713745,0.7029734253883362,0.47304728627204895,0.6500087976455688,0.629841685295105,0.5751425623893738,0.6661508083343506,0.6740322113037109,0.5890365242958069,0.54572594165802,0.5786154270172119,0.48767733573913574,0.604300320148468,0.509972333908081,0.5054853558540344,0.5103012323379517,0.5189085006713867,0.7247931957244873,0.4605579376220703,0.46294015645980835,0.5425155758857727,0.43969371914863586,0.7046498656272888,0.608484148979187,0.728135883808136,0.6291221380233765,0.5838658213615417,0.5405647158622742,0.657684862613678,0.7459561228752136,0.6499800682067871,0.6710268259048462,0.5418457388877869,0.5456479787826538,0.6353269815444946,0.5602536201477051,0.4396693706512451,0.49430611729621887,0.558752179145813,0.5270984768867493,0.6738139986991882,0.4812552332878113,0.4812825918197632,0.5637226104736328,0.5076295137405396,0.46441876888275146,0.6046529412269592,0.48256319761276245,0.6821159720420837,0.7948676347732544,0.5383111834526062,0.5651098489761353,0.5047081708908081,0.5159553289413452,0.6171311140060425,0.463433176279068,0.756353497505188,0.5351580381393433,0.4770982563495636,0.49718523025512695,0.6524909734725952,0.5720751881599426,0.5868114829063416,0.5943066477775574,0.678692102432251,0.7315229773521423,0.46963754296302795,0.5363934636116028,0.5645960569381714,0.6530781984329224,0.6386720538139343,0.6652336716651917,0.6860867738723755,0.5090547204017639,0.4690335690975189,0.5310745239257812,0.4121183156967163,0.451729953289032,0.5095471143722534,0.6213261485099792,0.5024846196174622,0.6150693297386169,0.6660659909248352,0.7728301882743835,0.528014063835144,0.6636410355567932,0.5087435245513916,0.7082210779190063,0.3999323546886444,0.5690517425537109,0.6261842250823975,0.6737796068191528,0.3403119742870331,0.7276500463485718,0.5005033016204834,0.6724675297737122,0.7763088941574097,0.642619252204895,0.4793267250061035,0.5193462371826172,0.49257445335388184,0.4968952238559723,0.48685982823371887,0.49913841485977173,0.7098336815834045,0.5500718951225281,0.6602256298065186,0.5272109508514404,0.5307616591453552,0.5163483023643494,0.6097152233123779,0.6205193996429443,0.5669875144958496,0.4924634099006653,0.5826009511947632,0.6608341336250305,0.525436282157898,0.5128284692764282,0.49712011218070984,0.6688089370727539,0.5400209426879883,0.6310662031173706,0.6768273711204529,0.447064608335495,0.5274891257286072,0.483501672744751,0.6475023627281189,0.5405294299125671,0.7322062253952026,0.6666536927223206,0.6364901661872864,0.4490683376789093,0.5514147877693176,0.6213998794555664,0.4095037579536438,0.49915677309036255,0.5801554918289185,0.5064688324928284,0.46193262934684753,0.7049500346183777,0.5301560759544373,0.658582329750061,0.4784375727176666,0.4716232120990753,0.5031388401985168,0.6751217842102051,0.5556908845901489,0.5138509273529053,0.6489666104316711,0.6367025375366211,0.59073805809021,0.597724437713623,0.5881971716880798,0.5643046498298645,0.5326668620109558,0.407187819480896,0.6233302354812622,0.5512335300445557,0.4940892159938812,0.5316139459609985,0.49578166007995605,0.5362305045127869,0.5036514401435852,0.6584631204605103,0.4646088480949402,0.705610990524292,0.6091811060905457,0.600865364074707,0.59574294090271,0.6424150466918945,0.6319482326507568,0.6861798763275146,0.7330760359764099,0.6211986541748047,0.6099370121955872,0.5895975828170776,0.39627745747566223,0.5366856455802917,0.4852364659309387,0.4898069500923157,0.5480297207832336,0.5553179383277893,0.6550337672233582,0.49310195446014404,0.6021469235420227,0.5357147455215454,0.6618906855583191,0.6386535167694092,0.4646647572517395,0.5695887207984924,0.6960023045539856,0.5722864866256714,0.47321417927742004,0.4813445508480072,0.554801344871521,0.5095705389976501,0.5839976072311401,0.623999297618866,0.6074432134628296,0.6793228983879089,0.5283879637718201,0.5830863118171692,0.585315465927124,0.3518190383911133,0.572769284248352,0.674796462059021,0.5672441720962524,0.5013582706451416,0.500780463218689,0.4723885655403137,0.5489845871925354,0.7278630137443542,0.5951344966888428,0.6607539057731628,0.6727895736694336,0.5515008568763733,0.6275434494018555,0.5826408863067627,0.5526657700538635,0.500435471534729,0.628371000289917,0.507531464099884,0.5823046565055847,0.5009180903434753,0.6093329191207886,0.5047855377197266,0.6079299449920654,0.6010580062866211,0.6336513757705688,0.6248921155929565,0.3395962119102478,0.5509368777275085,0.5368835926055908,0.5405135154724121,0.6278324723243713,0.6331691741943359,0.5331842303276062,0.4932871162891388,0.5022034645080566,0.5043999552726746,0.6151111721992493,0.46938857436180115,0.6652448773384094,0.5994920134544373,0.5275024771690369,0.5119258165359497,0.462922066450119,0.6009127497673035,0.575603723526001,0.5154741406440735,0.4678173065185547,0.5014585256576538,0.5557010173797607,0.6131290197372437,0.6803788542747498,0.49418672919273376,0.6451271772384644,0.51493901014328,0.6745457053184509,0.584490180015564,0.49793070554733276,0.5497446656227112,0.5059214234352112,0.7398138642311096,0.6773037314414978,0.5129063129425049,0.6429556012153625,0.33942803740501404,0.6621092557907104,0.47702962160110474,0.47613880038261414,0.5012892484664917,0.5938505530357361,0.4589226543903351,0.6864015460014343,0.461823433637619,0.5183606147766113,0.6843059659004211,0.6781761646270752,0.5238663554191589,0.5389823913574219,0.64437335729599,0.5050737857818604,0.6263347864151001,0.5059484243392944,0.49635088443756104,0.5936484336853027,0.47863948345184326,0.6728876233100891,0.4680848717689514,0.36957406997680664,0.6184514760971069,0.47019439935684204,0.47820669412612915,0.6646340489387512,0.571499764919281,0.7974955439567566,0.6474461555480957,0.6660339832305908,0.5542458891868591,0.49814316630363464,0.5946019291877747,0.6641973853111267,0.5663426518440247,0.7076430320739746,0.6265784502029419,0.6022151708602905,0.6750275492668152,0.5447077751159668,0.6568481922149658,0.5635420680046082,0.47181040048599243,0.5405490398406982,0.6477656960487366,0.5216400027275085,0.5164216160774231,0.5045493841171265,0.5582987070083618,0.5368908643722534,0.5697320699691772,0.6243489980697632,0.3680257797241211,0.5099966526031494,0.5903748273849487,0.5773026347160339,0.7557204365730286,0.5204949378967285,0.6120502948760986,0.4766550660133362,0.4660528302192688,0.47469648718833923,0.6684116721153259,0.5229124426841736,0.729106068611145,0.7415571808815002,0.6829651594161987,0.4929037392139435,0.488506942987442,0.6641696095466614,0.4876980781555176,0.5661249160766602,0.7343924641609192,0.48347556591033936,0.5090487003326416,0.6697719097137451,0.5125392079353333,0.581904947757721,0.5074899196624756,0.48605072498321533,0.49738848209381104,0.6552549004554749,0.5897265672683716,0.49716246128082275,0.6373479962348938,0.46465030312538147,0.5097969174385071,0.7771402597427368,0.610397219657898,0.6408872604370117,0.6578227877616882,0.7319269776344299,0.6746935844421387,0.6258113384246826,0.5559407472610474,0.5158527493476868,0.6759514212608337,0.6928271055221558,0.35435861349105835,0.6596136689186096,0.6999039649963379,0.6792064905166626,0.4806493818759918,0.4699331223964691,0.5926966071128845,0.4457402229309082,0.6386780738830566,0.4842327833175659,0.6485402584075928,0.5046963095664978,0.6246370673179626,0.48102495074272156,0.46496567130088806,0.5880016684532166,0.4977080523967743,0.5201829671859741,0.6844645142555237,0.7627595663070679,0.6037338376045227,0.5499463081359863,0.5357294678688049,0.6601150035858154,0.6684142351150513,0.6062899827957153,0.6075423955917358,0.5719943642616272,0.5668595433235168,0.46592462062835693,0.7223780155181885,0.5395746231079102,0.6647239923477173,0.5634390711784363,0.7436419725418091,0.577941358089447,0.6121793389320374,0.5084033608436584,0.47163665294647217,0.3702573776245117,0.5595723986625671,0.5964821577072144,0.6512186527252197,0.6152395606040955,0.511165201663971,0.5672177076339722,0.5108796954154968,0.6206711530685425,0.5843771696090698,0.5891668200492859,0.5239174962043762,0.6599103808403015,0.5968565344810486,0.4605560600757599,0.5694512128829956,0.5053899884223938,0.5343849658966064,0.45954596996307373,0.6823639273643494,0.5749124884605408,0.5218630433082581,0.4769233465194702,0.47709184885025024,0.6032830476760864,0.6095828413963318,0.5246049761772156,0.5354710817337036,0.5448614954948425,0.4893723428249359,0.3321552872657776,0.6538350582122803,0.7244001030921936,0.6004865765571594,0.6426425576210022,0.5932814478874207,0.4619140625,0.6798982620239258,0.5150162577629089,0.5581793189048767,0.6273040175437927,0.6623098254203796,0.4408208727836609,0.6316226720809937,0.5597312450408936,0.6751629710197449,0.47595691680908203,0.7207347750663757,0.6749127507209778,0.5291470885276794,0.4799399971961975,0.6226856708526611,0.6747575402259827,0.6286075115203857,0.4613554775714874,0.6413372159004211,0.6036738157272339,0.6855636239051819,0.36810725927352905,0.5296730995178223,0.3942340910434723,0.5710115432739258,0.677395224571228,0.5663697123527527,0.475666880607605,0.631212592124939,0.4655769169330597,0.5262961983680725,0.6258569955825806,0.7150635123252869,0.6592286229133606,0.5823211073875427,0.7056505084037781,0.5874122977256775,0.7640538215637207,0.5524490475654602,0.6316177248954773,0.5059214234352112,0.5244308710098267,0.6217128038406372,0.6282902956008911,0.6194378733634949,0.5518656373023987,0.6572254300117493,0.6870192885398865,0.7198866605758667,0.4859493672847748,0.7596369981765747,0.5106422901153564,0.5009666085243225,0.533706784248352,0.6789554357528687,0.6657758355140686,0.5147742033004761,0.6076219081878662,0.46565115451812744,0.5953444242477417,0.5287951231002808,0.45599085092544556,0.662792980670929,0.5262086987495422,0.5296573638916016,0.5053890347480774,0.6706634163856506,0.48064395785331726,0.5039333701133728,0.5421745777130127,0.6162258982658386,0.5050169825553894,0.5115752816200256,0.5139663219451904,0.6368975043296814,0.7842465043067932,0.5200669765472412,0.6443887948989868,0.4918277859687805,0.598362386226654,0.7269453406333923,0.6380537748336792,0.5023095607757568,0.7312650084495544,0.5128335356712341,0.49111229181289673,0.48665890097618103,0.6413832306861877,0.6599635481834412,0.6181685924530029,0.5334338545799255,0.5058844685554504,0.6005169749259949,0.5123255252838135,0.8009316325187683,0.5228080749511719,0.5932685136795044,0.6570653319358826,0.5970019698143005,0.48808109760284424,0.5118640661239624,0.39707037806510925,0.6501832604408264,0.5070778727531433,0.6259921193122864,0.6721823811531067,0.6142835021018982,0.7157596349716187,0.5482105016708374,0.5290251970291138,0.6781202554702759,0.6368626356124878,0.5885981321334839,0.7189337611198425,0.52906733751297,0.5986997485160828,0.5504094362258911,0.47086864709854126,0.5961806178092957,0.5206875801086426,0.7309340834617615,0.3881164789199829,0.7110751271247864,0.6766970753669739,0.5210214257240295,0.5089645385742188,0.5609898567199707,0.645376980304718,0.4882400929927826,0.6169729232788086,0.6840102076530457,0.5461171865463257,0.499644011259079,0.5355225205421448,0.5218585133552551,0.802276611328125,0.6692847013473511,0.4806513786315918,0.6363613605499268,0.7769975066184998,0.6316474676132202,0.6448020339012146,0.5819359421730042,0.6567245721817017,0.5212525129318237,0.7857495546340942,0.6866270899772644,0.6032830476760864,0.7360023260116577,0.4673089385032654,0.4894725978374481,0.5109774470329285,0.6158781051635742,0.4681098461151123,0.5163873434066772,0.43533700704574585,0.475997656583786,0.6418500542640686,0.5372115969657898,0.5248011946678162,0.653566300868988,0.7846419215202332,0.6098108291625977,0.5223202705383301,0.6138414144515991,0.4501935541629791,0.6386867165565491,0.6689615249633789,0.7250553369522095,0.5297702550888062,0.7296379804611206,0.3890722692012787,0.6286173462867737,0.6692137718200684,0.6071462035179138,0.6443972587585449,0.5944351553916931,0.5145530700683594,0.6004977226257324,0.5989341735839844,0.4784625172615051,0.4666678309440613,0.4641338586807251,0.49878743290901184,0.4792281985282898,0.5705179572105408,0.6628879904747009,0.6700305342674255,0.7261068224906921,0.5373032093048096,0.495608389377594,0.5567739009857178,0.47310855984687805,0.664501428604126,0.5235229134559631,0.47470995783805847,0.638174295425415,0.7366051077842712,0.6461097002029419,0.5418627262115479,0.7271787524223328,0.3665928244590759,0.4904951751232147,0.5976017117500305,0.5697230100631714,0.7242522835731506,0.6629115343093872,0.4706181585788727,0.5473181009292603,0.5938542485237122,0.6325660347938538,0.6100775599479675,0.7067145705223083,0.35136187076568604,0.5815571546554565,0.43825575709342957,0.6505870223045349,0.4305875599384308,0.6066369414329529,0.6738273501396179,0.5711220502853394,0.47115471959114075,0.5967315435409546],\"y\":[0.7412950396537781,0.9055919051170349,0.07807721197605133,0.8400321006774902,0.7459098100662231,0.7530006170272827,0.13837070763111115,0.855019748210907,0.2289867401123047,0.5221748352050781,0.3492039740085602,0.15212048590183258,0.5042905807495117,0.9024638533592224,0.31741511821746826,0.3350176513195038,0.8201393485069275,0.806567370891571,0.7817467451095581,0.6382091045379639,0.7892680764198303,0.612670361995697,0.6739625930786133,0.9013058543205261,0.35939642786979675,0.2826012670993805,0.5377161502838135,0.8821461200714111,0.8286138772964478,0.684575080871582,0.4448436498641968,0.5064404010772705,0.18465480208396912,0.6813498139381409,0.40577948093414307,0.20413006842136383,0.3072526156902313,0.444441020488739,0.5111711621284485,0.7362996339797974,0.5753598213195801,0.6742232441902161,0.13472044467926025,0.30804678797721863,0.24749575555324554,0.5128145813941956,0.9204363226890564,0.28403937816619873,0.3449794352054596,0.4494358003139496,0.44719699025154114,0.9139132499694824,0.4420577883720398,0.7633892893791199,0.944076418876648,0.8423852920532227,0.47766023874282837,0.09005028754472733,0.6031142473220825,0.7247423529624939,0.16277830302715302,0.024808553978800774,0.8148370385169983,0.7677406072616577,0.7374101877212524,0.4940645396709442,0.4481363594532013,0.5632861256599426,0.7714356184005737,0.8958993554115295,0.754296600818634,0.923967719078064,0.17471309006214142,0.7693784236907959,0.8046554923057556,0.20171676576137543,0.797542929649353,0.5273840427398682,0.9194907546043396,0.8815814852714539,0.3904900550842285,0.9500865340232849,0.4875650703907013,0.15228749811649323,0.4575638771057129,0.5283381342887878,0.719401478767395,0.061607688665390015,0.593253493309021,0.7226511836051941,0.015028640627861023,0.7558926343917847,0.7818360924720764,0.5967317819595337,0.5577835440635681,0.5535985827445984,0.11250265687704086,0.11005375534296036,0.7412828803062439,0.8976003527641296,0.9554417729377747,0.23589308559894562,0.7690622210502625,0.9431278109550476,0.018338052555918694,0.7763317823410034,0.01054408960044384,0.7173627614974976,0.7146241068840027,0.721596896648407,0.14306874573230743,0.30137187242507935,0.3766816556453705,0.4565041959285736,0.5096368789672852,0.7017064094543457,0.48958620429039,0.10135970264673233,0.7599778175354004,0.30460837483406067,0.9637637138366699,0.38098567724227905,0.49799156188964844,0.97230064868927,0.348443865776062,0.41843181848526,0.7972947955131531,0.6967661380767822,0.4940827190876007,0.7562791109085083,0.7691124081611633,0.3310244381427765,0.9519484639167786,0.8175058960914612,0.9023610353469849,0.7375904321670532,0.5135446786880493,0.4838641881942749,0.7759226560592651,0.6898562908172607,0.026960771530866623,0.7987871766090393,0.7632352709770203,0.5313894152641296,0.4217292070388794,0.5027139782905579,0.1415977030992508,0.6927719116210938,0.8193808794021606,0.39014995098114014,0.8085082769393921,0.7379069328308105,0.3407394587993622,0.9291830062866211,0.8335439562797546,0.7042438387870789,0.4451608657836914,0.9355126023292542,0.47929078340530396,0.7132939696311951,0.5054774284362793,0.8031373023986816,0.6789746284484863,0.12434078007936478,0.034964390099048615,0.465859979391098,0.8065783977508545,0.5124568343162537,0.9639219641685486,0.8095926642417908,0.7561905384063721,0.950779139995575,0.5880643725395203,0.6682828664779663,0.7967109680175781,0.8153080344200134,0.9425061345100403,0.44271185994148254,0.7025614976882935,0.9991609454154968,0.9492967128753662,0.08523345738649368,0.5402339696884155,0.9234398007392883,0.3715439438819885,0.4654078781604767,0.17063459753990173,0.2670743763446808,0.5498315095901489,0.6258074045181274,0.7298845052719116,0.6405131220817566,0.4544498026371002,0.7352283596992493,0.5663901567459106,0.681111752986908,0.7450355291366577,0.4686393737792969,0.2975078225135803,0.7222743630409241,0.9292298555374146,0.790330708026886,0.7724155783653259,0.7572993636131287,0.47467347979545593,0.6431530714035034,0.7663711905479431,0.7317211627960205,0.7804328203201294,0.47834640741348267,0.525351881980896,0.6313735842704773,0.9124440550804138,0.31214791536331177,0.6882485151290894,0.5512973070144653,0.9382710456848145,0.3493407368659973,0.7595881223678589,0.7884783744812012,0.47768494486808777,0.3865460455417633,0.5900427103042603,0.6574374437332153,0.8959786891937256,0.7822428345680237,0.38245081901550293,0.3584301769733429,0.6115841269493103,0.49421197175979614,0.5428943634033203,0.44582289457321167,0.707961916923523,0.8942119479179382,0.577025830745697,0.803646445274353,0.7523929476737976,0.3165787160396576,0.5168732404708862,0.2611018121242523,0.6069368124008179,0.7750077843666077,0.9092178344726562,0.8259332180023193,0.6739411354064941,0.7450456023216248,0.2879113554954529,0.7734305262565613,0.4533436596393585,0.504575252532959,0.16043388843536377,0.3563248813152313,0.5960754752159119,0.4284623861312866,0.7678434252738953,0.4628547430038452,0.9632424116134644,0.39984187483787537,0.7701904773712158,0.11347748339176178,0.36022064089775085,0.05231181159615517,0.34025776386260986,0.45089834928512573,0.22809934616088867,0.7181188464164734,0.3601014316082001,0.8485597968101501,0.7741699814796448,0.14601904153823853,0.757624089717865,0.8160266876220703,0.6205704212188721,0.5780529379844666,0.7568022012710571,0.5914570689201355,0.9310957789421082,0.523604691028595,0.9624249339103699,0.7128720283508301,0.4060564637184143,0.7727645039558411,0.7647743225097656,0.49255305528640747,0.4273458421230316,0.18115778267383575,0.9098115563392639,0.9226595759391785,0.1395254284143448,0.17416909337043762,0.9751158356666565,0.7517279982566833,0.7225339412689209,0.7133941650390625,0.7121194005012512,0.31531915068626404,0.4220837652683258,0.05265608802437782,0.22945120930671692,0.2428034245967865,0.11979559808969498,0.8660455346107483,0.9999938011169434,0.6500136852264404,0.891431450843811,0.789865255355835,0.7648866772651672,0.5428322553634644,0.31156688928604126,0.039546530693769455,0.5504492521286011,0.776460587978363,0.2427224963903427,0.725971519947052,0.9571604132652283,0.7868980765342712,0.5754642486572266,0.3996075689792633,0.1822349578142166,0.7350071668624878,0.1998520791530609,0.8009995222091675,0.250802606344223,0.7819908261299133,0.5864188075065613,0.8309874534606934,0.9874559044837952,0.22105973958969116,0.4186460077762604,0.2681661546230316,0.6195876598358154,0.5296024084091187,0.28254857659339905,0.7957341074943542,0.8130370378494263,0.9281917214393616,0.005566568113863468,0.5501798391342163,0.8379398584365845,0.9584105014801025,0.8176142573356628,0.6546384692192078,0.904626190662384,0.41523420810699463,0.6900283098220825,0.7048293948173523,0.8246976137161255,0.3781541883945465,0.7259418964385986,0.9460832476615906,0.8592398762702942,0.718701183795929,0.07920216768980026,0.6055342555046082,0.30180174112319946,0.7969233989715576,0.45660462975502014,0.4973664879798889,0.7692645192146301,0.38729846477508545,0.8137614727020264,0.07872156798839569,0.8262327313423157,0.46021077036857605,0.9460585117340088,0.6762955784797668,0.4260900914669037,0.2981828451156616,0.8083725571632385,0.44582289457321167,0.7952351570129395,0.3657028079032898,0.5809749364852905,0.590204656124115,0.33876895904541016,0.7700849175453186,0.7227802276611328,0.5801507234573364,0.874606192111969,0.6858854293823242,0.1390402466058731,0.4177923798561096,0.45417889952659607,0.7930124402046204,0.7627909183502197,0.44465577602386475,0.9073786735534668,0.7602968215942383,0.5148934125900269,0.8233357667922974,0.8359239101409912,0.07645396143198013,0.8197523951530457,0.83147794008255,0.5940820574760437,0.6774657368659973,0.7981452345848083,0.486593097448349,0.606823742389679,0.7158157229423523,0.28340235352516174,0.46639204025268555,0.65680330991745,0.5046037435531616,0.17685042321681976,0.9660560488700867,0.4673914611339569,0.39860060811042786,0.4280628561973572,0.359948068857193,0.7135416865348816,0.7197504639625549,0.7441738843917847,0.7756494879722595,0.7123977541923523,0.4520338475704193,0.7376489043235779,0.4578417241573334,0.3704828917980194,0.8947060108184814,0.8557654023170471,0.7870326042175293,0.7451980710029602,0.1364479660987854,0.769040584564209,0.4688272774219513,0.813984215259552,0.8167203664779663,0.5506582260131836,0.4572513997554779,0.7543739080429077,0.9072083830833435,0.6903668642044067,0.7425689101219177,0.028588302433490753,0.8189588785171509,0.24369901418685913,0.9368594288825989,0.46247628331184387,0.7253865599632263,0.764866054058075,0.4430680572986603,0.2827523648738861,0.44410058856010437,0.8188289403915405,0.7668832540512085,0.5202585458755493,0.5274946093559265,0.48390138149261475,0.14652526378631592,0.5451211333274841,0.5765485167503357,0.8449938297271729,0.7862347364425659,0.42879313230514526,0.3649314045906067,0.4153534173965454,0.35519546270370483,0.5403853058815002,0.5539787411689758,0.7312666177749634,0.7582463026046753,0.803063690662384,0.42528486251831055,0.2121100276708603,0.13291652500629425,0.8570998907089233,0.16932792961597443,0.7572855353355408,0.1600903570652008,0.7766492366790771,0.6834060549736023,0.9612987637519836,0.5244299173355103,0.2538907527923584,0.5274402499198914,0.2129296213388443,0.7522791028022766,0.4499230682849884,0.4049715995788574,0.6125888824462891,0.7285618185997009,0.2837781608104706,0.6909601092338562,0.8172498941421509,0.5859668254852295,0.9101000428199768,0.6149734258651733,0.37471744418144226,0.7379047870635986,0.04942968115210533,0.44932055473327637,0.43402373790740967,0.9039404988288879,0.36059609055519104,0.9752137660980225,0.6883957386016846,0.4800475537776947,0.6310689449310303,0.589060366153717,0.6032170057296753,0.5709595680236816,0.8037976026535034,0.9563245177268982,0.5885713696479797,0.7215448021888733,0.4336009621620178,0.8407523036003113,0.5346458554267883,0.6530142426490784,0.8795984983444214,0.48372480273246765,0.9934417605400085,0.789635419845581,0.3747005760669708,0.9254264831542969,0.2661948502063751,0.7286441326141357,0.6006759405136108,0.9633792638778687,0.7499811053276062,0.10629819333553314,0.9789026379585266,0.6513805985450745,0.7303596138954163,0.31716442108154297,0.1773148626089096,0.7017151713371277,0.44504788517951965,0.5331927537918091,0.03561399132013321,0.7483653426170349,0.6920408010482788,0.5397258400917053,0.22221633791923523,0.428193062543869,0.6981313228607178,0.7714664340019226,0.6379948258399963,0.5830787420272827,0.4382821023464203,0.8835093975067139,0.724224328994751,0.2630918622016907,0.6471944451332092,0.6461197137832642,0.29543089866638184,0.895877480506897,0.2756916880607605,0.3769211769104004,0.27790722250938416,0.9221122860908508,0.7327208518981934,0.8750897645950317,0.8049740791320801,0.7909919023513794,0.8258401155471802,0.7522146701812744,0.7395521402359009,0.7811788320541382,0.14877614378929138,0.7152705788612366,0.38711458444595337,0.5282760858535767,0.635270357131958,0.8170539140701294,0.7716048359870911,0.3743176758289337,0.5101791620254517,0.5983219742774963,0.034590717405080795,0.8155496716499329,0.29655542969703674,0.42917099595069885,0.7076058387756348,0.7900952100753784,0.6157126426696777,0.5980226397514343,0.8037750124931335,0.8028819561004639,0.8754022717475891,0.8159372210502625,0.3563298285007477,0.452256977558136,0.39460840821266174,0.6575382947921753,0.7064090371131897,0.17078977823257446,0.8047059178352356,0.6024551391601562,0.5429280400276184,0.08286627382040024,0.4037315547466278,0.8399072885513306,0.4388923943042755,0.7294279932975769,0.6424669027328491,0.23912861943244934,0.4503639042377472,0.7457898855209351,0.7440304756164551,0.45676425099372864,0.8029561638832092,0.4480453133583069,0.6635405421257019,0.8010919094085693,0.7782803773880005,0.9265486598014832,0.7849661707878113,0.3018304109573364,0.3927508294582367,0.8924129605293274,0.5771799683570862,0.8329342603683472,0.45810094475746155,0.7440313696861267,0.48207250237464905,0.1489686220884323,0.39437028765678406,0.7627133727073669,0.7522786855697632,0.6405516266822815,0.5256834030151367,0.31741032004356384,0.5243582129478455,0.7569035291671753,0.08739014714956284,0.6293962597846985,0.7376148104667664,0.4754932224750519,0.17838287353515625,0.7333369851112366,0.5262674689292908,0.9229738116264343,0.7701123952865601,0.5099257230758667,0.18136917054653168,0.017202237620949745,0.8477903604507446,0.8176755905151367,0.25722813606262207,0.36022064089775085,0.4411335289478302,0.9150890111923218,0.42652130126953125,0.5064173936843872,0.45126840472221375,0.7509844303131104,0.8563616871833801,0.5440194606781006,0.5440248847007751,0.6517786383628845,0.778096616268158,0.8025198578834534,0.5731940865516663,0.14793047308921814,0.7253003120422363,0.7122347354888916,0.5001733303070068,0.7555987238883972,0.7669575214385986,0.31572243571281433,0.8850041031837463,0.7437952160835266,0.7520141005516052,0.8782812356948853,0.9293621182441711,0.5223605632781982,0.6882193088531494,0.5157918334007263,0.0701616182923317,0.028227629140019417,0.5170807838439941,0.34716761112213135,0.1507917046546936,0.34379488229751587,0.7484471201896667,0.5036591291427612,0.8246926069259644,0.6491960883140564,0.5621964931488037,0.2758331894874573,0.4971877932548523,0.25907742977142334,0.693300187587738,0.46658799052238464,0.31987157464027405,0.027916360646486282,0.7642418742179871,0.7955312132835388,0.7452354431152344,0.1667880415916443,0.8106692433357239,0.4487815797328949,0.7058690190315247,0.8670659065246582,0.7536958456039429,0.49730151891708374,0.9530816674232483,0.45469924807548523,0.8625595569610596,0.5779127478599548,0.8295020461082458,0.6847282648086548,0.7059887051582336,0.6620568633079529,0.702560544013977,0.5013009905815125,0.8501589894294739,0.8179000020027161,0.6503486633300781,0.27996230125427246,0.7924427390098572,0.44380006194114685,0.9076876640319824,0.31572243571281433,0.9147294759750366,0.5987620949745178,0.11698063462972641,0.06489550322294235,0.7416607141494751,0.9032770395278931,0.5348048210144043,0.6586489677429199,0.6926265358924866,0.3381958305835724,0.640523374080658,0.4001173973083496,0.16215898096561432,0.21350187063217163,0.5860117673873901,0.9939999580383301,0.7606371641159058,0.9274972081184387,0.43532630801200867,0.3126973509788513,0.6141940355300903,0.95411616563797,0.9690901637077332,0.6916749477386475,0.2705456614494324,0.9306614398956299,0.6448538899421692,0.691909909248352,0.7478474378585815,0.7736480832099915,0.52720707654953,0.6901441812515259,0.9488219618797302,0.5398833751678467,0.8072166442871094,0.28552475571632385,0.7472057938575745,0.6596114635467529,0.7097722887992859,0.015108765102922916,0.7146634459495544,0.6317809224128723,0.8271880745887756,0.25947847962379456,0.44253361225128174,0.2072710394859314,0.7105748057365417,0.7403566837310791,0.9259963035583496,0.4740900695323944,0.3446076214313507,0.9915066361427307,0.82087641954422,0.7419581413269043,0.8856799602508545,0.7161059975624084,0.5450204610824585,0.04322706162929535,0.4096856415271759,0.32060039043426514,0.8739013075828552,0.02149795927107334,0.26420459151268005,0.7388734221458435,0.03422735258936882,0.6314604878425598,0.0821472555398941,0.6203494071960449,0.717411994934082,0.46689262986183167,0.12229826301336288,0.45439401268959045,0.46758750081062317,0.03316675126552582,0.29469987750053406,0.17293837666511536,0.3584539294242859,0.015270492061972618,0.7654126286506653,0.6519533395767212,0.7756492495536804,0.25806498527526855,0.5074640512466431,0.8933531641960144,0.7536986470222473,0.6095984578132629,0.6550390720367432,0.7681275606155396,0.7616528272628784,0.3117122948169708,0.7431378364562988,0.8132963180541992,0.5568944215774536,0.5196232795715332,0.7276462316513062,0.44281408190727234,0.6090608835220337,0.8213483095169067,0.403739333152771,0.8299108147621155,0.8182677626609802,0.5501798391342163,0.1900087296962738,0.43197932839393616,0.9422543048858643,0.4724873900413513,0.649642288684845,0.5611218214035034,0.4539962708950043,0.3485449552536011,0.7433243989944458,0.7309921979904175,0.6347786784172058,0.921028733253479,0.46837562322616577,0.9322274327278137,0.248226135969162,0.4997343420982361,0.3721848726272583,0.2620590627193451,0.5415729880332947,0.7240701913833618,0.3480311930179596,0.48699575662612915,0.3644706904888153,0.3832864463329315,0.4039608836174011,0.18039570748806,0.32975178956985474,0.06387607008218765,0.9553914070129395,0.5182139873504639,0.34079307317733765,0.7539407014846802,0.6449683308601379,0.45395803451538086,0.7737594842910767,0.8832563161849976,0.4606882631778717,0.15430301427841187,0.4731026887893677,0.03781553730368614,0.5196407437324524,0.4135662913322449,0.0,0.7756731510162354,0.24407891929149628,0.9082858562469482,0.8367719054222107,0.3448692560195923,0.42346876859664917,0.7724162340164185,0.5452994704246521,0.9227328896522522,0.5844134092330933,0.8373494744300842,0.3750753402709961,0.16699250042438507,0.0299141276627779,0.9931885600090027,0.4644143283367157,0.9145812392234802,0.9438735246658325,0.620372474193573,0.4196995198726654,0.9320091605186462,0.3297784626483917,0.4306335747241974,0.014902360737323761,0.8652451038360596,0.8117676973342896,0.9509621262550354,0.34549763798713684,0.6263744831085205,0.02152233012020588,0.8807439208030701,0.794249951839447,0.40166518092155457,0.6285743117332458,0.7927166819572449,0.6255338788032532,0.2004057914018631,0.8202465176582336,0.48287433385849,0.773946225643158,0.11410622298717499,0.7663723826408386,0.9622042775154114,0.722751259803772,0.6710253357887268,0.4691379964351654,0.4009549915790558,0.7857083082199097,0.7681793570518494,0.10556688159704208,0.3958536684513092,0.408869206905365,0.7571649551391602,0.30218473076820374,0.8242453336715698,0.5882310271263123,0.758570671081543,0.5330188274383545,0.9694952964782715,0.28487271070480347,0.5856426358222961,0.7378835678100586,0.03966686502099037,0.8877607583999634,0.20260146260261536,0.31115037202835083,0.7270787954330444,0.6649587154388428,0.29146960377693176,0.617668628692627,0.7658483386039734,0.7013261914253235,0.8795984983444214,0.48256057500839233,0.8000797033309937,0.8504176139831543,0.29319125413894653,0.48487672209739685,0.498972088098526,0.8758661150932312,0.4351106584072113,0.7135599255561829,0.5213302373886108,0.28632810711860657,0.183210089802742,0.33251628279685974,0.6679726243019104,0.7610914707183838,0.029432345181703568,0.3357560932636261,0.7354165315628052,0.7255894541740417,0.2348228096961975,0.7315950393676758,0.6525349020957947,0.7228982448577881,0.4692709743976593,0.9107111096382141,0.9581087827682495,0.4732470214366913,0.5777969360351562,0.6279031038284302,0.7713606357574463,0.8358840346336365,0.4787670075893402,0.5791673064231873,0.9558172225952148,0.28403937816619873,0.43346551060676575,0.8339632153511047,0.270364910364151,0.2478569746017456,0.9367926716804504,0.12196391820907593,0.27283814549446106,0.7466617226600647,0.2771633267402649,0.44452860951423645,0.4718136787414551,0.04626718908548355,0.3416943848133087,0.715455174446106,0.4871840178966522,0.8802538514137268,0.02128572203218937,0.5197464823722839,0.2755735218524933,0.7304080724716187,0.9766029715538025,0.34573104977607727,0.4277436137199402,0.635947585105896,0.5895202159881592,0.2709085941314697,0.9114900827407837,0.5141395926475525,0.7676622867584229,0.8777523040771484,0.7891895771026611,0.6954213976860046,0.586295485496521,0.4619182348251343,0.7576099038124084,0.19890327751636505,0.15184196829795837,0.7255894541740417,0.4827759265899658,0.7202202677726746,0.6052156686782837,0.8158842921257019,0.5664160847663879,0.6786394119262695,0.7477025389671326,0.8112577795982361,0.44476673007011414,0.4078971743583679,0.6334044337272644,0.7133502960205078,0.9184051752090454,0.502625048160553,0.7395380139350891,0.1623104065656662,0.7870513796806335,0.6319354772567749,0.7573836445808411,0.6105102300643921,0.4910184144973755,0.7611663341522217,0.4895193576812744,0.39065346121788025,0.4665803611278534,0.5046088099479675,0.021604005247354507,0.4988476037979126,0.8177109956741333,0.8071942329406738,0.17168563604354858,0.8064038753509521,0.8375136852264404,0.16705843806266785,0.6927328705787659,0.2255208045244217,0.5973560810089111,0.9900837540626526,0.6635422110557556,0.8915433287620544,0.8436300754547119,0.5673191547393799,0.42238283157348633,0.3207915723323822,0.8376135230064392,0.3765616714954376,0.30283474922180176,0.2825993299484253,0.48913928866386414,0.45759397745132446,0.4607228934764862,0.9722514152526855,0.45787909626960754,0.0709361732006073,0.1358603984117508,0.5613214373588562,0.5877241492271423,0.7139885425567627,0.5457333326339722,0.941506564617157,0.2687842547893524,0.8968793749809265,0.7871445417404175,0.31035515666007996,0.34143394231796265,0.16386832296848297,0.3768965005874634,0.017011119052767754,0.7597481608390808,0.47512713074684143,0.910632312297821,0.8258667588233948,0.9244294166564941,0.9552127718925476,0.8141085505485535,0.2842482626438141,0.14005473256111145,0.7309269905090332,0.7734663486480713,0.8229068517684937,0.2924695312976837,0.7605807185173035,0.45365285873413086,0.7273033857345581,0.2179412990808487,0.5335002541542053,0.32369959354400635,0.24706828594207764,0.6499840617179871,0.3515370488166809,0.6240259408950806,0.671860933303833,0.3223296105861664,0.932930588722229,0.7780142426490784,0.03635641932487488,0.7073633074760437,0.7215469479560852,0.27352771162986755,0.8839516639709473,0.7208397388458252,0.5241039991378784,0.9894404411315918,0.10722088068723679,0.8855822682380676,0.026975983753800392,0.13936418294906616,0.7701411247253418,0.7309722304344177,0.8470134735107422,0.7579483985900879,0.6062357425689697,0.611828625202179,0.4453635811805725,0.6405007839202881,0.9319286346435547,0.7173356413841248,0.28228169679641724,0.27292224764823914,0.4750955104827881,0.38254186511039734,0.4667079746723175,0.3072010576725006,0.516758918762207,0.5202994346618652,0.744895339012146,0.8251621127128601,0.775516927242279,0.6233264207839966,0.7020213603973389,0.6843565106391907,0.8034409880638123,0.11609317362308502,0.2132607251405716,0.3150928318500519,0.5291612148284912,0.9040815234184265,0.1346708983182907,0.5362995862960815,0.7587721943855286,0.12731388211250305,0.5328649878501892,0.3673165440559387,0.39364859461784363,0.5768614411354065,0.09582215547561646,0.8121979832649231,0.1539827436208725,0.7750211358070374,0.9491506814956665,0.7199074029922485,0.6354697942733765,0.2792729437351227,0.39193403720855713,0.8719948530197144,0.33206480741500854,0.7558910250663757,0.7477124333381653,0.6111266613006592,0.5753310322761536,0.806684672832489,0.749591052532196,0.38128358125686646,0.3283676207065582,0.41211241483688354,0.44196996092796326,0.4967096447944641,0.733473002910614,0.15409395098686218,0.5074843764305115,0.4939277470111847,0.5003280639648438,0.4577224850654602,0.7883378863334656,0.6758273839950562,0.4137994349002838,0.4972299039363861,0.35739168524742126,0.13304468989372253,0.9462626576423645,0.38449233770370483,0.4661095142364502,0.05393251031637192,0.5726641416549683,0.009396865032613277,0.9393794536590576,0.7553187608718872,0.7773148417472839,0.7077192068099976,0.1850685030221939,0.4657026529312134,0.6024892330169678,0.3326415419578552,0.2300374060869217,0.5594634413719177,0.9185420274734497,0.6752223372459412,0.7374125719070435,0.7417071461677551,0.6676523089408875,0.8512632846832275,0.9576685428619385,0.6744616627693176,0.25132498145103455,0.7439597249031067,0.5453343987464905,0.35700923204421997,0.7292925715446472,0.9070768356323242,0.7970924973487854,0.6629735231399536,0.7339909076690674,0.07208538800477982,0.9207974076271057,0.379038006067276,0.7554817795753479,0.35361579060554504,0.38456109166145325,0.34278616309165955,0.9364927411079407,0.7365190386772156,0.3179662227630615,0.8423264026641846,0.7877807021141052,0.7746044993400574,0.600894033908844,0.22917361557483673,0.7267736792564392,0.43731746077537537,0.49460646510124207,0.6389039754867554,0.5598848462104797,0.3011816442012787,0.8922499418258667,0.5253486633300781,0.23947784304618835,0.7991448044776917,0.5677099227905273,0.28387442231178284,0.7074435949325562,0.5104398727416992,0.007865853607654572,0.4920613765716553,0.8265079259872437,0.6617348194122314,0.6967078447341919,0.5345010161399841,0.5837709307670593,0.827931821346283,0.4177786111831665,0.8864865303039551,0.4331264793872833,0.09457578510046005,0.8378479480743408,0.7849976420402527,0.3161294162273407,0.39201268553733826,0.42973676323890686,0.8779963254928589,0.4989379346370697,0.8203427791595459,0.4412044286727905,0.08797331899404526,0.6595376133918762,0.7740684151649475,0.6820371150970459,0.5324139595031738,0.7549777626991272,0.4599156677722931,0.10044609010219574,0.7001426219940186,0.7024763822555542,0.8388577699661255,0.5522702932357788,0.4272371828556061,0.6765573024749756,0.5479822754859924,0.2004057914018631,0.8990499973297119,0.6997280716896057,0.4991728365421295,0.34464892745018005,0.561725378036499,0.42730164527893066,0.7503787279129028,0.4306264817714691,0.9154220223426819,0.6724622845649719,0.3602592349052429,0.5653811097145081,0.5080252289772034,0.2710658311843872,0.4501382112503052,0.25656116008758545,0.4962465763092041,0.6636266708374023,0.7578815817832947,0.5852353572845459,0.7559564709663391,0.3194858431816101,0.44803351163864136,0.769993007183075,0.758712887763977,0.5557867884635925,0.28364184498786926,0.6234633326530457,0.21219727396965027,0.7940089702606201,0.12342536449432373,0.7846365571022034,0.24868270754814148,0.28428560495376587,0.13708055019378662,0.9298927783966064,0.3688197433948517,0.5114827752113342,0.7617796063423157,0.9077969789505005,0.5939541459083557,0.7714263796806335,0.018716299906373024,0.23583899438381195,0.7745081782341003,0.7081932425498962,0.41882362961769104,0.25794896483421326,0.5213462114334106,0.6636398434638977,0.44896355271339417,0.8511443734169006,0.04048040881752968,0.957003653049469,0.4418083131313324,0.37087175250053406,0.7946214079856873,0.7519235014915466,0.8359111547470093,0.3212049901485443,0.3102513253688812,0.7834644317626953,0.12252028286457062,0.6979892253875732,0.7199074029922485,0.8338090777397156,0.03914066031575203,0.8452159762382507,0.43687719106674194,0.7121005654335022,0.14900366961956024,0.7969755530357361,0.5907328724861145,0.6858909726142883,0.7299811840057373,0.16122524440288544,0.6134206056594849,0.7536367177963257,0.41314443945884705,0.9244441986083984,0.40608540177345276,0.6380588412284851,0.5172348618507385,0.9366306662559509,0.7137523293495178,0.7413267493247986,0.2219933569431305,0.5995787382125854,0.22099287807941437,0.3820786476135254,0.3431825637817383,0.8263537883758545,0.5466887354850769,0.5633543729782104,0.7582187056541443,0.35811635851860046,0.868233323097229,0.1459011733531952,0.8306837677955627,0.7645907402038574,0.12566010653972626,0.2431415468454361,0.7028464674949646,0.34683847427368164,0.5447311401367188,0.7112102508544922,0.9333966374397278,0.8819842338562012,0.7624152302742004,0.593253493309021,0.9417424201965332,0.6616560220718384,0.8238211870193481,0.678832471370697,0.6075680255889893,0.7522582411766052,0.7198299169540405,0.9779654741287231,0.6497994065284729,0.719284176826477,0.5569740533828735,0.7120246291160583,0.3952789604663849,0.7399784326553345,0.3733309805393219,0.6382735967636108,0.6553581953048706,0.8558478951454163,0.3413080871105194,0.3228183388710022,0.3446575999259949,0.7332786917686462,0.5669088363647461,0.7161985039710999,0.46681568026542664,0.49614429473876953,0.8541478514671326,0.02328396774828434,0.3165222108364105,0.5446540117263794,0.7601286172866821,0.2748297154903412,0.4270113408565521,0.577576756477356,0.4155040979385376,0.7499861717224121,0.4278234541416168,0.7218402624130249,0.6961450576782227,0.7638261318206787,0.7374568581581116,0.9436582922935486,0.1610502302646637,0.5381262302398682,0.3210916221141815,0.5012010335922241,0.6167744398117065,0.8221014142036438,0.6253290176391602,0.39265328645706177,0.9824953079223633,0.11704204231500626,0.7670757174491882,0.8044831156730652,0.7473316192626953,0.64335697889328,0.005515686701983213,0.8183861970901489,0.27600356936454773,0.7539960741996765,0.1295626312494278,0.16177618503570557,0.4739725887775421,0.5892438888549805,0.7100878953933716,0.3867701292037964,0.4266669452190399,0.7351102828979492,0.8955833911895752,0.7963598966598511,0.4798012375831604,0.7834360003471375,0.6866462826728821,0.655699610710144,0.770702064037323,0.5770910382270813,0.6791878342628479,0.7697944045066833,0.09519917517900467,0.48624157905578613,0.6762385368347168,0.2591993808746338,0.4151686728000641,0.4661296606063843,0.08763997256755829,0.736294686794281,0.40165284276008606,0.44406723976135254,0.35023635625839233,0.8064513206481934,0.4248206913471222,0.7468551397323608,0.7741961479187012,0.7165949940681458,0.9792668223381042,0.5683790445327759,0.6499398350715637,0.7128101587295532,0.9386102557182312,0.8009937405586243,0.4111289381980896,0.7413496375083923,0.7022315859794617,0.7569040656089783,0.45742666721343994,0.32963407039642334,0.33093497157096863,0.39211925864219666,0.8137332201004028,0.11195880174636841,0.6631264686584473,0.2418888956308365,0.49730080366134644,0.7749649882316589,0.7512004375457764,0.743945837020874,0.7218286991119385,0.11465927213430405,0.6338874101638794,0.7435928583145142,0.7608959078788757,0.6110004186630249,0.04075039550662041,0.6540577411651611,0.7898116707801819,0.494097501039505,0.7765926718711853,0.6909378170967102,0.8000079989433289,0.4506441056728363,0.07493214309215546,0.7261927127838135,0.7255898118019104,0.8454923629760742,0.8310635685920715,0.3545692265033722,0.59824138879776,0.4170859456062317,0.6629400849342346,0.8994660377502441,0.8393285274505615,0.6555737257003784,0.6066503524780273,0.28962770104408264,0.5849241614341736,0.7959738373756409,0.581855833530426,0.6184011101722717,0.7588906288146973,0.20598290860652924,0.2595464587211609,0.23459790647029877,0.7640342116355896,0.7329649329185486,0.8612304329872131,0.3913308382034302,0.7105617523193359,0.8508025407791138,0.5167373418807983,0.5749239921569824,0.8671199679374695,0.8647000789642334,0.7173746824264526,0.6319190859794617,0.390280544757843,0.2836095690727234,0.8135075569152832,0.9258615970611572,0.6622226238250732,0.6685912013053894,0.06978451460599899,0.26775163412094116,0.7965539693832397,0.6827371120452881,0.7439253330230713,0.3932173252105713,0.8877650499343872,0.805355429649353,0.7856079936027527,0.2991921603679657,0.3678929805755615,0.533419668674469,0.7311769127845764,0.46190518140792847,0.26152464747428894,0.965955913066864,0.11706282943487167,0.7332482933998108,0.5462618470191956,0.8157856464385986,0.5177415609359741,0.46474066376686096,0.4343729615211487,0.6614346504211426,0.5821351408958435,0.6224601864814758,0.48379844427108765,0.9105313420295715,0.6548049449920654,0.33673709630966187,0.7492267489433289,0.8386273384094238,0.6032835841178894,0.1236310675740242,0.47545722126960754,0.6496050953865051,0.03707676753401756,0.5421611070632935,0.7076713442802429,0.7484467029571533,0.03419544920325279,0.9546253085136414,0.5745305418968201,0.8892215490341187,0.7009852528572083,0.7581599354743958,0.7213932275772095,0.4866074323654175,0.8333340287208557,0.47589993476867676,0.6147722601890564,0.8009105324745178,0.7749648690223694,0.43039917945861816,0.066521555185318,0.7331123352050781,0.7156441807746887,0.539527416229248,0.4638484716415405,0.028599673882126808,0.7069089412689209,0.763533353805542,0.6955878734588623,0.23244602978229523,0.882129430770874,0.5445532202720642,0.6826249957084656,0.3709474802017212,0.009307656437158585,0.905174195766449,0.8769719004631042,0.7366393804550171,0.47754016518592834,0.009503722190856934,0.9858887195587158,0.570061445236206,0.60370934009552,0.12539415061473846,0.811137318611145,0.42078980803489685,0.6664087772369385,0.8285630941390991,0.9351662993431091,0.2661965489387512,0.4692670404911041,0.3722410202026367,0.1898467093706131,0.13037440180778503,0.06210442632436752,0.7276483774185181,0.4719620943069458,0.8092278242111206,0.4243629276752472,0.3606787323951721,0.44849586486816406,0.5858234167098999,0.6712684035301208,0.49198758602142334,0.7126737833023071,0.3582074046134949,0.8895686864852905,0.6105757355690002,0.2998232841491699,0.8313490152359009,0.4576725363731384,0.7172577381134033,0.4036104083061218,0.5777969360351562,0.39540791511535645,0.5281729698181152,0.8155553936958313,0.8191110491752625,0.8802250623703003,0.4520041048526764,0.053139828145504,0.37724557518959045,0.8907849788665771,0.4886867105960846,0.873801589012146,0.714694619178772,0.8336043953895569,0.8070487380027771,0.20851390063762665,0.2841886281967163,0.4423442482948303,0.9012142419815063,0.47393661737442017,0.8175145387649536,0.45219704508781433,0.8394739627838135,0.4427381455898285,0.7424898743629456,0.9226440787315369,0.7092663645744324,0.39774781465530396,0.9438586235046387,0.6199251413345337,0.7606693506240845,0.5615922808647156,0.9338616728782654,0.9672844409942627,0.6273000240325928,0.588241696357727,0.42784035205841064,0.4059462547302246,0.19810926914215088,0.07498524338006973,0.18813985586166382,0.7076207995414734,0.8135045170783997,0.7365001440048218,0.6676475405693054,0.7949095964431763,0.35406482219696045,0.8123911619186401,0.743449866771698,0.7113918662071228,0.7738777995109558,0.5820546746253967,0.0983949676156044,0.8158107399940491,0.2411518543958664,0.12683698534965515,0.7673514485359192,0.6868314146995544,0.07617319375276566,0.781681478023529,0.6029462814331055,0.4505310356616974,0.40265631675720215,0.8255845904350281,0.7710086107254028,0.4235304594039917,0.5313458442687988,0.4717560112476349,0.11497057229280472,0.4711363613605499,0.607033371925354,0.14986813068389893,0.49607181549072266,0.7513535022735596,0.4247884750366211,0.38466617465019226,0.0023220679722726345,0.5330778956413269,0.6538162231445312,0.7472545504570007,0.11517225205898285,0.34591132402420044,0.756249725818634,0.947742223739624,0.7227497100830078,0.042865172028541565,0.2725182771682739,0.7900682091712952,0.7666487097740173,0.33527472615242004,0.7985365986824036,0.41040128469467163,0.7386331558227539,0.12772300839424133,0.7222784161567688,0.7775090336799622,0.6078591346740723,0.7650828957557678,0.47511863708496094,0.920792818069458,0.7708849906921387,0.03458289057016373,0.3629646897315979,0.9032770395278931,0.5522763729095459,0.9166678786277771,0.435030996799469,0.7433856725692749,0.7416707277297974,0.3025208115577698,0.8692464232444763,0.6013510227203369,0.7264834046363831,0.5479533672332764,0.5068537592887878,0.1778726726770401,0.5514748096466064,0.700753927230835,0.4896557033061981,0.8196559548377991,0.9222681522369385,0.3839937150478363,0.9468182921409607,0.3435536324977875,0.6821728348731995,0.410199910402298,0.8581666350364685,0.6778143048286438,0.24147748947143555,0.42669638991355896,0.7674725651741028,0.9456378221511841,0.7890365123748779,0.27240461111068726,0.18042558431625366,0.19224022328853607,0.8966907262802124,0.8415555357933044,0.28066518902778625,0.8220230340957642,0.26697465777397156,0.31926241517066956,0.3591695725917816,0.8060210943222046,0.7261364459991455,0.5669408440589905,0.4646156430244446,0.33596712350845337,0.59603351354599,0.8476077318191528,0.39737656712532043,0.8745419979095459,0.7588819861412048,0.7425848245620728,0.41881194710731506,0.5071529150009155,0.8135071396827698,0.6847853064537048,0.633332371711731,0.6959676742553711,0.8241422176361084,0.24548380076885223,0.47096723318099976,0.8178181648254395,0.058677226305007935,0.3764057159423828,0.8003008365631104,0.457411527633667,0.31872084736824036,0.8572733998298645,0.44126254320144653,0.2740628719329834,0.553956151008606,0.42042553424835205,0.5592921376228333,0.7202802896499634,0.571089506149292,0.6592758297920227,0.742059588432312,0.7669126987457275,0.2412942349910736,0.17328612506389618,0.09064623713493347,0.7360429763793945,0.3800254166126251,0.707908034324646,0.2337355613708496,0.7563627362251282,0.7651854157447815,0.9726676344871521,0.6098265647888184,0.7340608239173889,0.6945693492889404,0.42078980803489685,0.9771201014518738,0.28430530428886414,0.530290961265564,0.8463205695152283,0.37608468532562256,0.5932793021202087,0.7509808540344238,0.7719495296478271,0.47908687591552734,0.5828251242637634,0.7718854546546936,0.438604474067688,0.8260167241096497,0.15858294069766998,0.394800066947937,0.7317537665367126,0.8289218544960022,0.19996502995491028,0.43211543560028076,0.8039682507514954,0.15614677965641022,0.8178707957267761,0.18529413640499115,0.5806146264076233,0.6302006244659424,0.37530791759490967,0.46352195739746094,0.7361069321632385,0.432904988527298,0.1691257357597351,0.4599774181842804,0.5466198325157166,0.48106375336647034,0.766136109828949,0.4608883261680603,0.34021684527397156,0.2809719145298004,0.04747205227613449,0.4233126938343048,0.7328399419784546,0.07718785852193832,0.019177183508872986,0.67843097448349,0.22181859612464905,0.42435526847839355,0.24909894168376923,0.7315887808799744,0.6814019083976746,0.37683752179145813,0.960693359375,0.6709511280059814,0.8534460663795471,0.14068587124347687,0.4296005070209503,0.1705087572336197,0.42293187975883484,0.8166589140892029,0.8252326250076294,0.44542717933654785,0.6635655760765076,0.6413993239402771,0.16782933473587036,0.21981732547283173,0.41473641991615295,0.15198659896850586,0.22846943140029907,0.6650165319442749,0.8353033661842346,0.7227811217308044,0.03805432468652725,0.16455906629562378,0.6291624307632446,0.7725546956062317,0.2758331894874573,0.361305832862854,0.37808215618133545,0.5126841068267822,0.5417422652244568,0.717301607131958,0.6059532761573792,0.6252593994140625,0.6425246596336365,0.7316475510597229,0.7026781439781189,0.6315236687660217,0.8587810397148132,0.5022158622741699,0.285874605178833,0.7376515865325928,0.5261926651000977,0.849589467048645,0.7785565257072449,0.5207231044769287,0.7230620980262756,0.44460055232048035,0.37533071637153625,0.5704479813575745,0.7273504734039307,0.4563922584056854,0.645845890045166,0.5584853887557983,0.9051607847213745,0.7587475776672363,0.8117600083351135,0.4327738881111145,0.4204508662223816,0.26697465777397156,0.6774023771286011,0.8078386783599854,0.742924690246582,0.19198866188526154,0.23788346350193024,0.18310004472732544,0.6569734811782837,0.7037107944488525,0.5242245197296143,0.289065420627594,0.7931194305419922,0.804370105266571,0.08382392674684525,0.5047074556350708,0.5788689851760864,0.17031146585941315,0.9068869352340698,0.7457394599914551,0.1040366068482399,0.7249232530593872,0.7940927147865295,0.794518768787384,0.6635640859603882,0.6235416531562805,0.5800563097000122,0.4611250162124634,0.778003990650177,0.6354506611824036,0.77757728099823,0.27745088934898376,0.8506640195846558,0.8516217470169067,0.8024120330810547,0.4103269875049591,0.13378867506980896,0.4294269382953644,0.7444698810577393,0.740470290184021,0.6196634769439697,0.03869827836751938,0.7829774618148804,0.9062491059303284,0.40547144412994385,0.8587250113487244,0.48775187134742737,0.7834159731864929,0.7374163866043091,0.0130692757666111,0.5575333833694458,0.5630125403404236,0.6363918781280518,0.7392873764038086,0.7501804232597351,0.5169925689697266,0.32123637199401855,0.876074492931366,0.854839563369751,0.5919830799102783,0.4469902217388153,0.29849618673324585,0.4852132499217987,0.34321367740631104,0.2967621982097626,0.8738262057304382,0.6381953358650208,0.5030184388160706,0.41887977719306946,0.7025246620178223,0.4274497628211975,0.6985000967979431,0.34575071930885315,0.4653152823448181,0.45643681287765503,0.3853387236595154,0.6777388453483582],\"z\":[0.42681723833084106,0.5622828602790833,0.38726308941841125,0.49589312076568604,0.5652061700820923,0.4236930310726166,0.3848969042301178,0.46276265382766724,0.4137631356716156,0.4144081473350525,0.39884912967681885,0.3712746500968933,0.5101723074913025,0.49407967925071716,0.40474820137023926,0.42451414465904236,0.5248783826828003,0.4279862940311432,0.5322704315185547,0.4385056793689728,0.4920773506164551,0.48425647616386414,0.5481917858123779,0.5571815371513367,0.43687906861305237,0.42688167095184326,0.40185296535491943,0.5687710642814636,0.43390634655952454,0.4947987198829651,0.39808741211891174,0.4764291048049927,0.4433715045452118,0.4631836712360382,0.4259087145328522,0.39578601717948914,0.47108063101768494,0.5174452662467957,0.5282536745071411,0.5494378209114075,0.44449737668037415,0.44299590587615967,0.439567893743515,0.4501130282878876,0.41237789392471313,0.5297315120697021,0.5778825283050537,0.40538060665130615,0.49003615975379944,0.47307392954826355,0.40279409289360046,0.5080795288085938,0.4090900421142578,0.4249453842639923,0.5671012997627258,0.49839502573013306,0.45003506541252136,0.4093743562698364,0.45616239309310913,0.4326072335243225,0.3762897551059723,0.4090975224971771,0.5131823420524597,0.43120473623275757,0.46124595403671265,0.4642583131790161,0.4145908057689667,0.40317732095718384,0.43204429745674133,0.5150938630104065,0.4754406213760376,0.47956523299217224,0.40965536236763,0.5240509510040283,0.445678174495697,0.43873876333236694,0.4792003333568573,0.47956860065460205,0.5760769248008728,0.5293525457382202,0.4917871356010437,0.4653717279434204,0.3984057605266571,0.42671459913253784,0.4029892683029175,0.5304034948348999,0.5697853565216064,0.4312503933906555,0.5429528951644897,0.4354814291000366,0.39094623923301697,0.5391196608543396,0.4281955659389496,0.5280250310897827,0.3955122232437134,0.5370140671730042,0.38957297801971436,0.4179592430591583,0.44927892088890076,0.5555930733680725,0.47513318061828613,0.4133334159851074,0.426318883895874,0.5368697047233582,0.3786564767360687,0.5446382164955139,0.4848608076572418,0.56270831823349,0.43044114112854004,0.5257802605628967,0.37540432810783386,0.4814164340496063,0.4704872667789459,0.5268539190292358,0.4620235860347748,0.4285539388656616,0.3899916112422943,0.39852190017700195,0.5632695555686951,0.4501081705093384,0.5852593779563904,0.4109072685241699,0.3797725737094879,0.4926339387893677,0.4784964621067047,0.4141223430633545,0.5118518471717834,0.4393170177936554,0.4756087362766266,0.46327200531959534,0.4319930970668793,0.4825856387615204,0.5650493502616882,0.42990484833717346,0.5784879326820374,0.49312400817871094,0.47500213980674744,0.37961098551750183,0.43237316608428955,0.4499896764755249,0.44605404138565063,0.4230009615421295,0.42642319202423096,0.4522576928138733,0.5038440823554993,0.39384862780570984,0.37853723764419556,0.5150192379951477,0.4399568438529968,0.4179896116256714,0.5108168721199036,0.4906303584575653,0.4059758186340332,0.5836594700813293,0.4489862620830536,0.5448195338249207,0.5212031602859497,0.5732388496398926,0.471752792596817,0.45877590775489807,0.3783431053161621,0.4342411160469055,0.5128225684165955,0.38420483469963074,0.44549068808555603,0.5276084542274475,0.4390629231929779,0.4379613697528839,0.4806273877620697,0.5191588997840881,0.43852195143699646,0.4871535897254944,0.5210660099983215,0.5095933675765991,0.430695116519928,0.4597892165184021,0.4762401580810547,0.5266488194465637,0.4840051233768463,0.5002726316452026,0.5047143697738647,0.40343108773231506,0.457079142332077,0.4809773862361908,0.49697214365005493,0.38649776577949524,0.44522973895072937,0.39614343643188477,0.4396888315677643,0.48135754466056824,0.5708397030830383,0.494546502828598,0.45580676198005676,0.42665937542915344,0.5386970639228821,0.4502393305301666,0.45095551013946533,0.40460675954818726,0.40229955315589905,0.426239550113678,0.5574750900268555,0.4448174238204956,0.420219749212265,0.4346686005592346,0.5087538957595825,0.45206502079963684,0.513343334197998,0.5562448501586914,0.41845518350601196,0.5169849991798401,0.3806409239768982,0.4355849027633667,0.5134610533714294,0.40172699093818665,0.5125434994697571,0.44750314950942993,0.5886633992195129,0.4723129868507385,0.5303350687026978,0.43445664644241333,0.46617308259010315,0.4646364748477936,0.4618786573410034,0.5200748443603516,0.5743341445922852,0.4454343616962433,0.41045549511909485,0.4604633152484894,0.4578550159931183,0.3917580842971802,0.3925170600414276,0.48070988059043884,0.5582871437072754,0.5385174751281738,0.4287164509296417,0.4485831558704376,0.4483397603034973,0.40531352162361145,0.4690110683441162,0.41437065601348877,0.42703357338905334,0.535523533821106,0.5045433640480042,0.5271502137184143,0.4959101974964142,0.42910274863243103,0.4006863534450531,0.42034339904785156,0.39566630125045776,0.382351815700531,0.42068204283714294,0.48550328612327576,0.4950103759765625,0.4880083501338959,0.5289096236228943,0.4095343053340912,0.49286872148513794,0.4031938910484314,0.5505362749099731,0.3951919376850128,0.45287197828292847,0.4269188940525055,0.4049503803253174,0.4030953049659729,0.4262693226337433,0.5677774548530579,0.40104034543037415,0.45685628056526184,0.5048545598983765,0.37721899151802063,0.43122369050979614,0.4395627975463867,0.490391343832016,0.4840555787086487,0.4671819508075714,0.4822033941745758,0.5414890050888062,0.5328441262245178,0.4659218192100525,0.428329735994339,0.41437748074531555,0.49880093336105347,0.49416130781173706,0.527032196521759,0.4686177670955658,0.39382144808769226,0.5322849750518799,0.5290325880050659,0.373940646648407,0.38247910141944885,0.5419960021972656,0.4345267117023468,0.45281675457954407,0.5577663779258728,0.4421612024307251,0.47984498739242554,0.4059488773345947,0.38124555349349976,0.4084424674510956,0.38906338810920715,0.4004437327384949,0.5342375636100769,0.5427037477493286,0.4698179066181183,0.5169463753700256,0.5323113799095154,0.4400596022605896,0.4796009659767151,0.4004807472229004,0.40681758522987366,0.3992626965045929,0.4470205008983612,0.3946547508239746,0.5706770420074463,0.47644472122192383,0.5410423278808594,0.5332913398742676,0.5065447092056274,0.4291549324989319,0.5611070394515991,0.4496834874153137,0.5366820693016052,0.3911714255809784,0.4348984956741333,0.43708348274230957,0.49666139483451843,0.4789908826351166,0.37984147667884827,0.5227150917053223,0.45162904262542725,0.47513532638549805,0.4797142744064331,0.47092562913894653,0.5206691026687622,0.5313994884490967,0.5810574889183044,0.4188850522041321,0.4364648759365082,0.4475657641887665,0.507246732711792,0.4345570206642151,0.435988187789917,0.4948597550392151,0.5020423531532288,0.5285803079605103,0.49611395597457886,0.44142523407936096,0.4636869728565216,0.4284515082836151,0.5334210991859436,0.5306311249732971,0.4485717713832855,0.4112652838230133,0.45949438214302063,0.47683146595954895,0.5322088003158569,0.5274045467376709,0.4721166491508484,0.4322478771209717,0.48719656467437744,0.4575614929199219,0.428548127412796,0.44080793857574463,0.47144368290901184,0.49982133507728577,0.48866578936576843,0.504552960395813,0.44118109345436096,0.4442761242389679,0.48070988059043884,0.43973830342292786,0.4054839313030243,0.44635170698165894,0.4471271336078644,0.41076889634132385,0.5059115290641785,0.5676052570343018,0.4163118004798889,0.4756639897823334,0.43366947770118713,0.40848153829574585,0.430806428194046,0.4037194848060608,0.42980730533599854,0.4807891547679901,0.5134091377258301,0.48687243461608887,0.43092042207717896,0.47898733615875244,0.44457805156707764,0.44879212975502014,0.4271937906742096,0.4916016757488251,0.5209804177284241,0.5192054510116577,0.5265746712684631,0.4342794418334961,0.38972342014312744,0.46953436732292175,0.4357999861240387,0.4736675024032593,0.524729311466217,0.5456933379173279,0.46188968420028687,0.38495174050331116,0.5272626280784607,0.44327032566070557,0.5127027034759521,0.40839818120002747,0.4043946862220764,0.5680956244468689,0.44370517134666443,0.4373382329940796,0.5039307475090027,0.42857247591018677,0.4213155508041382,0.566789984703064,0.4367360472679138,0.4846319258213043,0.5015945434570312,0.5285183787345886,0.4498346447944641,0.4766978919506073,0.39835333824157715,0.4787028431892395,0.5278342962265015,0.4609390199184418,0.4395158588886261,0.5211062431335449,0.44339224696159363,0.44554319977760315,0.5613769292831421,0.5443397164344788,0.5117795467376709,0.4007451832294464,0.5289395451545715,0.41102737188339233,0.5739243030548096,0.519146740436554,0.4704659581184387,0.43753236532211304,0.4427827298641205,0.3931760787963867,0.40922895073890686,0.4409565329551697,0.4200614094734192,0.45104849338531494,0.394530713558197,0.4634621739387512,0.383197546005249,0.4608336091041565,0.47939518094062805,0.4460456371307373,0.4176310896873474,0.4984089434146881,0.40066054463386536,0.5029069781303406,0.4178568720817566,0.4387274980545044,0.45063716173171997,0.43969687819480896,0.4318196177482605,0.4216623902320862,0.5094454884529114,0.43402186036109924,0.3797239363193512,0.4789085388183594,0.3994579315185547,0.43526729941368103,0.3958393335342407,0.5453846454620361,0.4809258282184601,0.5860541462898254,0.44994017481803894,0.3854438364505768,0.3869098722934723,0.3875613808631897,0.429678350687027,0.5174664258956909,0.42750582098960876,0.43217092752456665,0.5669907331466675,0.40282872319221497,0.4456428587436676,0.4259909987449646,0.46953821182250977,0.49170982837677,0.5382977724075317,0.47360700368881226,0.5178018808364868,0.379154771566391,0.4173339009284973,0.4786060154438019,0.5919564962387085,0.4571232795715332,0.5633243322372437,0.47712889313697815,0.39098119735717773,0.54393470287323,0.45685046911239624,0.5061564445495605,0.5251051783561707,0.512028694152832,0.577961266040802,0.4776129424571991,0.4404847025871277,0.4078081548213959,0.5104843378067017,0.4937644600868225,0.5042574405670166,0.578361988067627,0.5112033486366272,0.5561440587043762,0.5408517122268677,0.46911346912384033,0.5824632048606873,0.43361207842826843,0.5710441470146179,0.4741538465023041,0.46781301498413086,0.451416552066803,0.4203052818775177,0.5019300580024719,0.445431649684906,0.43729543685913086,0.4321083724498749,0.3761405944824219,0.48512786626815796,0.3989565074443817,0.5225539207458496,0.39308393001556396,0.5561849474906921,0.510809600353241,0.5335294008255005,0.39285367727279663,0.4097745418548584,0.43179014325141907,0.4646306037902832,0.4420764148235321,0.44014498591423035,0.40775415301322937,0.5227576494216919,0.44006484746932983,0.44694289565086365,0.4404325783252716,0.49742263555526733,0.4029255509376526,0.5843284726142883,0.4686864912509918,0.42104414105415344,0.45791521668434143,0.5744730234146118,0.44988471269607544,0.47399041056632996,0.4273064434528351,0.4671013057231903,0.5026349425315857,0.5633959174156189,0.5401155948638916,0.4267386198043823,0.3820967972278595,0.5502326488494873,0.43012580275535583,0.5117640495300293,0.5273159742355347,0.4457627534866333,0.5271904468536377,0.4275992512702942,0.3913857638835907,0.42513421177864075,0.421892911195755,0.45258814096450806,0.40245312452316284,0.5157323479652405,0.4486561715602875,0.41880249977111816,0.5209181308746338,0.45731431245803833,0.4379224479198456,0.47547340393066406,0.5778896808624268,0.467910498380661,0.4048631489276886,0.418422669172287,0.43370184302330017,0.4818454086780548,0.4528527557849884,0.40256160497665405,0.42500120401382446,0.4284273684024811,0.42514798045158386,0.4037123918533325,0.40177011489868164,0.45456966757774353,0.3985807001590729,0.49812403321266174,0.4636411964893341,0.4151241183280945,0.5240808129310608,0.44935011863708496,0.49628540873527527,0.4352472722530365,0.4911704659461975,0.5138616561889648,0.49579954147338867,0.459277480840683,0.4265389144420624,0.5019805431365967,0.43406641483306885,0.46244293451309204,0.41445305943489075,0.5664429068565369,0.41475942730903625,0.44823506474494934,0.3956851363182068,0.46617552638053894,0.5187153220176697,0.37012672424316406,0.49420443177223206,0.48978257179260254,0.5407517552375793,0.45835891366004944,0.5230284333229065,0.40443846583366394,0.5235726833343506,0.4374419152736664,0.42008495330810547,0.46318307518959045,0.4809686541557312,0.5210186243057251,0.4313386082649231,0.565062940120697,0.5253422260284424,0.5838176608085632,0.4920280873775482,0.44972753524780273,0.3843728005886078,0.36910638213157654,0.4560669958591461,0.5304253697395325,0.4538394510746002,0.45287197828292847,0.42537757754325867,0.4805156886577606,0.5162642598152161,0.38563719391822815,0.47961512207984924,0.48477092385292053,0.46961671113967896,0.4587571918964386,0.5305176377296448,0.5308899879455566,0.4261937737464905,0.4229326844215393,0.4393089711666107,0.3977762758731842,0.4477669894695282,0.43839752674102783,0.3879401981830597,0.43629685044288635,0.5335833430290222,0.43279802799224854,0.4881361424922943,0.4493376612663269,0.44424179196357727,0.5773044228553772,0.5768245458602905,0.5211880803108215,0.5480988621711731,0.40748101472854614,0.42673730850219727,0.4667787253856659,0.47101566195487976,0.4589705765247345,0.3777320981025696,0.4018014371395111,0.5026862025260925,0.5197045803070068,0.5266018509864807,0.4813884198665619,0.4532395303249359,0.40056130290031433,0.3871101140975952,0.44597530364990234,0.4823114275932312,0.4393061101436615,0.42394566535949707,0.4162657558917999,0.4329836666584015,0.4336779713630676,0.4274282455444336,0.3864749073982239,0.511710524559021,0.47214049100875854,0.4568954110145569,0.5671874284744263,0.4295094609260559,0.5163179636001587,0.5694599747657776,0.4785366654396057,0.47812962532043457,0.41535890102386475,0.5248386263847351,0.5471418499946594,0.48748525977134705,0.5482088923454285,0.46723565459251404,0.39405959844589233,0.449553906917572,0.4483475685119629,0.438012957572937,0.46152061223983765,0.4416457414627075,0.48679718375205994,0.5724363327026367,0.43279802799224854,0.4975489675998688,0.47230973839759827,0.37812575697898865,0.42052680253982544,0.42953020334243774,0.5714514255523682,0.38897672295570374,0.5194304585456848,0.5492032170295715,0.40255045890808105,0.4757748544216156,0.49420109391212463,0.40562304854393005,0.43065476417541504,0.4694673717021942,0.4965406656265259,0.4923979938030243,0.4899180233478546,0.42703714966773987,0.47822096943855286,0.4770704209804535,0.4753423035144806,0.5486042499542236,0.5347944498062134,0.3993823826313019,0.5839820504188538,0.5320638418197632,0.431783527135849,0.4468561112880707,0.43221282958984375,0.4932103157043457,0.47902411222457886,0.5607529282569885,0.4785842299461365,0.5152198672294617,0.46434536576271057,0.42836010456085205,0.5494788885116577,0.49795520305633545,0.4751347303390503,0.5556639432907104,0.5233476161956787,0.43819332122802734,0.4494469463825226,0.47603848576545715,0.37912410497665405,0.4270203411579132,0.5620716214179993,0.5077617764472961,0.3920089900493622,0.45932114124298096,0.5468729138374329,0.5283000469207764,0.489613801240921,0.5539483428001404,0.4423879086971283,0.5204222798347473,0.4378393292427063,0.5206239223480225,0.4276304841041565,0.5242161750793457,0.4329665005207062,0.46988925337791443,0.5695711374282837,0.42099276185035706,0.44830000400543213,0.43836307525634766,0.48140424489974976,0.5282481908798218,0.3998526930809021,0.39049002528190613,0.43935883045196533,0.4642966687679291,0.4324283301830292,0.4510812759399414,0.42009779810905457,0.3987857699394226,0.4047466814517975,0.43943560123443604,0.46802785992622375,0.5346879959106445,0.40166717767715454,0.4576919674873352,0.49637383222579956,0.42355769872665405,0.48217839002609253,0.4550819396972656,0.43227100372314453,0.4573492407798767,0.46155405044555664,0.44902166724205017,0.43870070576667786,0.5248489379882812,0.523790717124939,0.45547568798065186,0.4292818605899811,0.441241055727005,0.43760043382644653,0.47719550132751465,0.5162429809570312,0.5131762027740479,0.4364648759365082,0.41508302092552185,0.4424751400947571,0.46854159235954285,0.40125715732574463,0.43829238414764404,0.5101397037506104,0.4686824679374695,0.4696428179740906,0.5580449104309082,0.44225406646728516,0.487703800201416,0.4841521978378296,0.5129431486129761,0.47436198592185974,0.45150241255760193,0.3790164589881897,0.4567141830921173,0.4341590702533722,0.4797500669956207,0.48923513293266296,0.4064940810203552,0.48376375436782837,0.41498658061027527,0.4275248050689697,0.4288848638534546,0.4090980291366577,0.43678367137908936,0.3904147744178772,0.5560310482978821,0.5251415371894836,0.49750277400016785,0.46189287304878235,0.5360943078994751,0.4286605715751648,0.42786186933517456,0.5210958123207092,0.4887677729129791,0.42700210213661194,0.3869463801383972,0.408468633890152,0.3938850164413452,0.5221468806266785,0.5141452550888062,0.4322495758533478,0.42086687684059143,0.5576224327087402,0.5207946300506592,0.40967538952827454,0.4164857566356659,0.4217207431793213,0.5191870927810669,0.481288343667984,0.5098020434379578,0.510648787021637,0.4969746768474579,0.3763439655303955,0.44838905334472656,0.49179866909980774,0.5245885848999023,0.5076501965522766,0.5711311101913452,0.4884222745895386,0.5152498483657837,0.48864850401878357,0.4922926127910614,0.4868376851081848,0.49530571699142456,0.46593543887138367,0.4502622187137604,0.5018677115440369,0.49498581886291504,0.4341626763343811,0.4308317005634308,0.5655187964439392,0.4357163608074188,0.49468517303466797,0.44612398743629456,0.43268701434135437,0.47215601801872253,0.43937647342681885,0.44685348868370056,0.405259907245636,0.4179920554161072,0.38013720512390137,0.43092015385627747,0.46513670682907104,0.5213724374771118,0.4743648171424866,0.5049887895584106,0.40860089659690857,0.45193207263946533,0.4303480088710785,0.4335796535015106,0.4156040549278259,0.47361844778060913,0.4533883333206177,0.48338961601257324,0.5077486038208008,0.4259898066520691,0.5620331764221191,0.5272108912467957,0.4681730568408966,0.4210406541824341,0.4155931770801544,0.4480689465999603,0.4135434329509735,0.49934935569763184,0.4448256194591522,0.4301989674568176,0.4311966300010681,0.5495967864990234,0.39912694692611694,0.4682256579399109,0.5514677166938782,0.5617170333862305,0.578361988067627,0.4906042516231537,0.4317275583744049,0.4496786296367645,0.40455734729766846,0.3907840847969055,0.4293122887611389,0.5490670204162598,0.5121205449104309,0.5581809282302856,0.46086984872817993,0.46261879801750183,0.3758082091808319,0.4123828113079071,0.4458117187023163,0.5508584976196289,0.4330989420413971,0.48842090368270874,0.5352153182029724,0.5584321022033691,0.4460521340370178,0.45503610372543335,0.4520800709724426,0.43794700503349304,0.4343707859516144,0.565518319606781,0.47857466340065,0.4859713912010193,0.46609997749328613,0.4418390095233917,0.4262089133262634,0.5228652358055115,0.4459443986415863,0.5309229493141174,0.5267923474311829,0.40538060665130615,0.43989965319633484,0.445234477519989,0.3960329592227936,0.38801172375679016,0.4764043688774109,0.38484078645706177,0.4243672490119934,0.49106302857398987,0.4690721929073334,0.504114031791687,0.3935244381427765,0.4084087610244751,0.49602389335632324,0.4867296516895294,0.4564330577850342,0.5588591694831848,0.4243144690990448,0.5307960510253906,0.40560153126716614,0.42838796973228455,0.48115089535713196,0.45267000794410706,0.4352229833602905,0.5116298198699951,0.42603352665901184,0.4321169853210449,0.48507004976272583,0.5125373601913452,0.5125281810760498,0.4982534945011139,0.43488508462905884,0.44903498888015747,0.4665891230106354,0.5189588665962219,0.42135265469551086,0.44132450222969055,0.37028568983078003,0.5584321022033691,0.515021800994873,0.44919219613075256,0.5348116159439087,0.5261727571487427,0.5391804575920105,0.48542407155036926,0.4537040889263153,0.4311421513557434,0.5150780081748962,0.5115138292312622,0.5393191576004028,0.4973098635673523,0.4987165331840515,0.3858986496925354,0.4495866298675537,0.38566088676452637,0.43464261293411255,0.4373021721839905,0.4408935308456421,0.471863716840744,0.38844141364097595,0.4468822181224823,0.38177141547203064,0.5080849528312683,0.5188614130020142,0.45949575304985046,0.4689291715621948,0.5032109618186951,0.4393001198768616,0.4369892179965973,0.44409608840942383,0.4589294493198395,0.4375949501991272,0.4022270143032074,0.4533606469631195,0.40203988552093506,0.5451361536979675,0.5036826729774475,0.4640745222568512,0.5826998353004456,0.507074773311615,0.5286930203437805,0.42278727889060974,0.47596848011016846,0.5080358386039734,0.44854736328125,0.40359124541282654,0.4073423445224762,0.5234076380729675,0.5056144595146179,0.5134798884391785,0.4941631555557251,0.4024259150028229,0.40498754382133484,0.3815450668334961,0.4229722023010254,0.4597368836402893,0.5541744232177734,0.396954208612442,0.5307437777519226,0.39658617973327637,0.5117223858833313,0.4331659972667694,0.4061338007450104,0.4422922730445862,0.39353933930397034,0.40709346532821655,0.3829275667667389,0.5622261762619019,0.47113126516342163,0.5849767327308655,0.4296746551990509,0.4945639669895172,0.4665083587169647,0.5200666189193726,0.4008637070655823,0.37774795293807983,0.4351009130477905,0.43058934807777405,0.44245445728302,0.4400668740272522,0.42648792266845703,0.4456632733345032,0.42944851517677307,0.4186785817146301,0.5234902501106262,0.4315843880176544,0.3944253623485565,0.44640856981277466,0.4320041835308075,0.45963114500045776,0.4834417402744293,0.39861658215522766,0.48155149817466736,0.41829437017440796,0.4290771186351776,0.5619614720344543,0.5443167686462402,0.4064217209815979,0.5291941165924072,0.43960341811180115,0.3845193684101105,0.5515300035476685,0.3791714608669281,0.5047110319137573,0.37963008880615234,0.37245509028434753,0.43211692571640015,0.4287520945072174,0.5071300268173218,0.5299993753433228,0.4592621624469757,0.5433403253555298,0.5083261132240295,0.4564951956272125,0.47706836462020874,0.42980507016181946,0.40394023060798645,0.40527743101119995,0.5101272463798523,0.4115382134914398,0.5272404551506042,0.4317830502986908,0.5202159285545349,0.38469165563583374,0.4528180658817291,0.43803268671035767,0.492949903011322,0.48800310492515564,0.45132559537887573,0.4417901933193207,0.42115119099617004,0.3852044343948364,0.38113918900489807,0.42373016476631165,0.4524427354335785,0.5533483624458313,0.3921189606189728,0.5009596943855286,0.46738696098327637,0.38980382680892944,0.5182310342788696,0.4465297758579254,0.4652278423309326,0.4128267765045166,0.38658714294433594,0.437599778175354,0.3897823393344879,0.43599972128868103,0.5797750353813171,0.5664576888084412,0.4755510985851288,0.4019845724105835,0.5165022015571594,0.4719979465007782,0.4882919192314148,0.4504871368408203,0.4418776333332062,0.43211275339126587,0.4088129699230194,0.4243362843990326,0.5676562190055847,0.5047010183334351,0.4787972867488861,0.48227038979530334,0.40038466453552246,0.4491328299045563,0.4268852174282074,0.37396422028541565,0.39428994059562683,0.5232939124107361,0.4304064214229584,0.509086549282074,0.44984957575798035,0.4365817904472351,0.4024795591831207,0.3966171443462372,0.4011721611022949,0.4293997883796692,0.5874489545822144,0.4052670896053314,0.3962862491607666,0.39681005477905273,0.40611302852630615,0.4515834450721741,0.5745473504066467,0.5043594241142273,0.42806920409202576,0.4545477628707886,0.37322095036506653,0.4093279242515564,0.45880937576293945,0.49003076553344727,0.383911669254303,0.5361965298652649,0.5344206094741821,0.4712959825992584,0.4403443932533264,0.42908185720443726,0.43743062019348145,0.4588698446750641,0.5278993248939514,0.47726112604141235,0.4060114920139313,0.4696444571018219,0.43798843026161194,0.4171067476272583,0.5590367317199707,0.5760104060173035,0.5128426551818848,0.4418831765651703,0.5646000504493713,0.4389069080352783,0.4970211982727051,0.4012742340564728,0.5123516321182251,0.4095137119293213,0.4900372326374054,0.44034692645072937,0.5884671807289124,0.4546339511871338,0.42307546734809875,0.45042943954467773,0.43080267310142517,0.4318215250968933,0.45388054847717285,0.3772517442703247,0.4294017553329468,0.5062570571899414,0.5262542963027954,0.5432054400444031,0.50495445728302,0.4780524671077728,0.5321317911148071,0.48332545161247253,0.38335755467414856,0.43433713912963867,0.5144059658050537,0.41421130299568176,0.42821159958839417,0.3926103711128235,0.39332062005996704,0.39106595516204834,0.47184592485427856,0.4832794964313507,0.4318651258945465,0.42664143443107605,0.4782567620277405,0.45576202869415283,0.47474706172943115,0.4874928593635559,0.45177921652793884,0.42732980847358704,0.4623079001903534,0.43348297476768494,0.4238987863063812,0.5066935420036316,0.42435818910598755,0.5147358775138855,0.43793854117393494,0.44854483008384705,0.5119299292564392,0.4337295591831207,0.5290108323097229,0.43104490637779236,0.43486693501472473,0.5276898145675659,0.45040297508239746,0.3950822353363037,0.4189511239528656,0.559910237789154,0.47570493817329407,0.5036178827285767,0.4611342251300812,0.44964098930358887,0.43963900208473206,0.41348177194595337,0.43937647342681885,0.5733495354652405,0.46205106377601624,0.4582664668560028,0.49510663747787476,0.45262983441352844,0.4350583851337433,0.4331711530685425,0.4855223000049591,0.5176698565483093,0.5026853680610657,0.40598294138908386,0.5265600085258484,0.38254353404045105,0.3944976031780243,0.494574636220932,0.42545750737190247,0.5274046063423157,0.4687446057796478,0.42871010303497314,0.5442964434623718,0.562027096748352,0.46049463748931885,0.5238810181617737,0.5522670745849609,0.4931422173976898,0.4996435046195984,0.405525803565979,0.5456822514533997,0.39682579040527344,0.4352579414844513,0.39582112431526184,0.4528566002845764,0.4424284100532532,0.39888596534729004,0.4325563609600067,0.5831225514411926,0.4575342833995819,0.47815003991127014,0.44836267828941345,0.5561900734901428,0.48661693930625916,0.4969739317893982,0.41827067732810974,0.39519640803337097,0.5489633083343506,0.4669415354728699,0.4091329574584961,0.3943219780921936,0.3885042071342468,0.5278712511062622,0.3960963189601898,0.5256728529930115,0.4182635247707367,0.5035466551780701,0.41138187050819397,0.40450042486190796,0.41934406757354736,0.4397284984588623,0.43446555733680725,0.4059580862522125,0.46214762330055237,0.4468209147453308,0.41503629088401794,0.44897690415382385,0.5664576888084412,0.4415837526321411,0.3942090570926666,0.48425647616386414,0.5093673467636108,0.42710787057876587,0.42121317982673645,0.4321010112762451,0.4236965477466583,0.5488491654396057,0.43469759821891785,0.3771073520183563,0.5268835425376892,0.4454718828201294,0.5129369497299194,0.48005211353302,0.520012378692627,0.45032402873039246,0.45995205640792847,0.4715062379837036,0.4833463430404663,0.5644748210906982,0.40046176314353943,0.4729420840740204,0.4385944604873657,0.41022989153862,0.43096715211868286,0.5258213877677917,0.44235676527023315,0.45003730058670044,0.4333243668079376,0.41504859924316406,0.4749198257923126,0.38518062233924866,0.49460282921791077,0.43968188762664795,0.4376400113105774,0.3927198648452759,0.5521625876426697,0.489359587430954,0.5012155175209045,0.5626102685928345,0.5868977904319763,0.5778551697731018,0.4960290491580963,0.5429528951644897,0.517643928527832,0.4884464740753174,0.5079219937324524,0.5180562734603882,0.4857933521270752,0.48539483547210693,0.4407055675983429,0.5755929350852966,0.4390871524810791,0.4972013831138611,0.39902135729789734,0.4928484857082367,0.4075393080711365,0.5666940808296204,0.40716680884361267,0.45937731862068176,0.47732678055763245,0.49966180324554443,0.4780241847038269,0.461995005607605,0.4163661599159241,0.5702229738235474,0.40291550755500793,0.4726438820362091,0.516377866268158,0.5245797038078308,0.47059112787246704,0.47627875208854675,0.4105333387851715,0.44373592734336853,0.42449751496315,0.39308038353919983,0.4821980893611908,0.5403307676315308,0.41066813468933105,0.5194255709648132,0.42725870013237,0.5570910573005676,0.42992135882377625,0.4342809021472931,0.43758028745651245,0.5383366942405701,0.3806352913379669,0.449535995721817,0.4062591791152954,0.41389864683151245,0.4934343099594116,0.4408688545227051,0.5454133749008179,0.4722096920013428,0.5389871597290039,0.4009394347667694,0.483909010887146,0.4560679793357849,0.42594262957572937,0.43901193141937256,0.42918887734413147,0.4390740990638733,0.4488605260848999,0.5174897313117981,0.38525527715682983,0.3756464123725891,0.3818092942237854,0.44329196214675903,0.4432392418384552,0.5070524215698242,0.4099765121936798,0.49671074748039246,0.5362985730171204,0.4379001259803772,0.4880140423774719,0.42057085037231445,0.4912751019001007,0.5032460689544678,0.44678938388824463,0.4417113661766052,0.5476343631744385,0.4319280982017517,0.400028258562088,0.43799057602882385,0.494771808385849,0.3865870237350464,0.4232999086380005,0.47364625334739685,0.4320434033870697,0.4396743178367615,0.5099441409111023,0.5145516991615295,0.49494799971580505,0.43953990936279297,0.5147369503974915,0.5027753710746765,0.4173643887042999,0.5524918437004089,0.5673705339431763,0.5295265316963196,0.46243369579315186,0.4286346733570099,0.5373530387878418,0.4260134994983673,0.4057616591453552,0.5663544535636902,0.4576748311519623,0.4251836836338043,0.519118070602417,0.4864928424358368,0.4220847487449646,0.49571871757507324,0.4391920566558838,0.42615363001823425,0.4841683804988861,0.39971470832824707,0.4022650420665741,0.5502601265907288,0.4242556691169739,0.4679293632507324,0.5469151139259338,0.42687761783599854,0.4678736925125122,0.42475423216819763,0.5628992319107056,0.4765535295009613,0.4295811653137207,0.4405118227005005,0.5171154141426086,0.4470946490764618,0.4463299810886383,0.5267138481140137,0.4358695149421692,0.4086247980594635,0.3883035480976105,0.5067532062530518,0.5136276483535767,0.44055280089378357,0.4440526068210602,0.5043641328811646,0.4281991422176361,0.42748698592185974,0.5501599907875061,0.482628732919693,0.5120059847831726,0.446871817111969,0.43504878878593445,0.40428513288497925,0.4136788249015808,0.4330422580242157,0.4116184115409851,0.4846982955932617,0.42106860876083374,0.43886834383010864,0.3967794179916382,0.42726239562034607,0.5074984431266785,0.4285516142845154,0.5314902663230896,0.42538630962371826,0.5629096031188965,0.5160326361656189,0.4834515452384949,0.47626301646232605,0.5236921310424805,0.5303880572319031,0.43167269229888916,0.4438247084617615,0.4053080081939697,0.397159606218338,0.4423953890800476,0.5833327770233154,0.43907615542411804,0.4541071057319641,0.3797478973865509,0.4179970324039459,0.4210487902164459,0.4731484353542328,0.5672761797904968,0.46936899423599243,0.5790204405784607,0.5116625428199768,0.5421603918075562,0.417123943567276,0.4112113118171692,0.38301464915275574,0.4467660188674927,0.41793954372406006,0.40379250049591064,0.5313584208488464,0.403052419424057,0.5555238723754883,0.39212048053741455,0.5289396643638611,0.48019087314605713,0.4993399381637573,0.5105242133140564,0.5496248602867126,0.42387834191322327,0.49581286311149597,0.41528892517089844,0.5713754296302795,0.4505482017993927,0.4415260851383209,0.442457914352417,0.49496543407440186,0.542138397693634,0.3992505669593811,0.5140365958213806,0.5453853607177734,0.39938321709632874,0.5293514132499695,0.507064700126648,0.4271371066570282,0.4301414489746094,0.5020524859428406,0.5178428888320923,0.5668256282806396,0.5578161478042603,0.4324159026145935,0.5701144933700562,0.4288407266139984,0.43296384811401367,0.5156967043876648,0.5363941788673401,0.43619993329048157,0.4321994483470917,0.4045007824897766,0.4269019663333893,0.5044354796409607,0.49057120084762573,0.3903735876083374,0.4939887821674347,0.38702836632728577,0.5623502731323242,0.42188403010368347,0.4578459560871124,0.3974735140800476,0.5546911358833313,0.5342053174972534,0.45372939109802246,0.46782827377319336,0.49144038558006287,0.4947006106376648,0.4753507673740387,0.47352373600006104,0.5160330533981323,0.4404570162296295,0.517134964466095,0.5021976232528687,0.42845672369003296,0.42220667004585266,0.5248708128929138,0.515283465385437,0.4551176428794861,0.45196837186813354,0.56512051820755,0.3960295617580414,0.42310288548469543,0.5039552450180054,0.4401158392429352,0.3737615942955017,0.4032219648361206,0.43197837471961975,0.4576386511325836,0.4482809901237488,0.4443404972553253,0.4979977309703827,0.43538177013397217,0.490727037191391,0.5237972736358643,0.38037052750587463,0.4393787980079651,0.49924543499946594,0.5229943990707397,0.5123740434646606,0.4753212630748749,0.4445973038673401,0.4071815311908722,0.4669528603553772,0.42859503626823425,0.46609997749328613,0.5124815106391907,0.46741998195648193,0.45390960574150085,0.44212886691093445,0.576805055141449,0.45023590326309204,0.39128729701042175,0.5025462508201599,0.5037307739257812,0.38690561056137085,0.4726264178752899,0.5471066832542419,0.43600186705589294,0.5081921219825745,0.43873336911201477,0.44553112983703613,0.511385977268219,0.4953783452510834,0.4020405411720276,0.5217592120170593,0.49810901284217834,0.5025312304496765,0.526222825050354,0.43242672085762024,0.5536181330680847,0.49376004934310913,0.4774540066719055,0.48042193055152893,0.5445369482040405,0.5628972053527832,0.4695104956626892,0.5321360230445862,0.47658488154411316,0.43773189187049866,0.44664591550827026,0.40151548385620117,0.4131608307361603,0.4410458505153656,0.3968781530857086,0.3725343942642212,0.52137291431427,0.5118343234062195,0.4602064788341522,0.48398131132125854,0.4432981312274933,0.4950811266899109,0.44244205951690674,0.4496360719203949,0.45151644945144653,0.4245333671569824,0.45069342851638794,0.42707809805870056,0.43562352657318115,0.39613205194473267,0.3938828706741333,0.4276709258556366,0.49839743971824646,0.42780187726020813,0.43565529584884644,0.4372992217540741,0.43589743971824646,0.40408748388290405,0.441944420337677,0.48647454380989075,0.5158364176750183,0.45020511746406555,0.3959166407585144,0.4309993386268616,0.5252891778945923,0.48742085695266724,0.4344097077846527,0.5245782732963562,0.42429229617118835,0.40155985951423645,0.49306443333625793,0.5109692215919495,0.4366500675678253,0.5064490437507629,0.4484488070011139,0.40441784262657166,0.4108198881149292,0.4410316050052643,0.47766217589378357,0.4521982967853546,0.4205966293811798,0.4524488151073456,0.4330720901489258,0.5037918090820312,0.49490615725517273,0.4395331144332886,0.47775596380233765,0.427442729473114,0.4227372705936432,0.43629908561706543,0.5275096297264099,0.4751318395137787,0.4303547143936157,0.5072306394577026,0.49409523606300354,0.4350614845752716,0.4572325646877289,0.4901985228061676,0.5714514255523682,0.5360713601112366,0.5811921954154968,0.486684650182724,0.4970373809337616,0.4257866442203522,0.46921104192733765,0.5452065467834473,0.4453783333301544,0.5659089684486389,0.5320751070976257,0.3847474753856659,0.4358249306678772,0.43805062770843506,0.5458477735519409,0.5219670534133911,0.43991804122924805,0.506195068359375,0.5060896873474121,0.5871060490608215,0.3991262912750244,0.5442306995391846,0.48085784912109375,0.5283691883087158,0.44568800926208496,0.39017462730407715,0.5060065984725952,0.48122021555900574,0.4670495092868805,0.516577422618866,0.404163658618927,0.38680073618888855,0.4032113552093506,0.58310866355896,0.49715879559516907,0.44178318977355957,0.48783767223358154,0.43761172890663147,0.41127631068229675,0.4007367491722107,0.5211561918258667,0.5607291460037231,0.5042084455490112,0.45950382947921753,0.408434122800827,0.4566503167152405,0.45467129349708557,0.5180600881576538,0.5457937717437744,0.44777268171310425,0.5072895288467407,0.5147246718406677,0.38036486506462097,0.4402610957622528,0.4743461608886719,0.4753158390522003,0.5550621151924133,0.518756091594696,0.408101886510849,0.5031507015228271,0.47665199637413025,0.4102931022644043,0.4018346071243286,0.4411627948284149,0.5245329737663269,0.44070300459861755,0.5181108117103577,0.4407411515712738,0.3976532220840454,0.3969477713108063,0.4437914788722992,0.4695446789264679,0.4314669966697693,0.44122248888015747,0.5497684478759766,0.516503632068634,0.42433997988700867,0.3862588703632355,0.43576356768608093,0.39325380325317383,0.5546833276748657,0.4062826633453369,0.4487243592739105,0.38764289021492004,0.4272483289241791,0.5080362558364868,0.4749106764793396,0.471927672624588,0.5635576248168945,0.5535179376602173,0.515283465385437,0.5677007436752319,0.4730093479156494,0.5285756587982178,0.519873857498169,0.47498854994773865,0.43348512053489685,0.510395348072052,0.5016094446182251,0.39798542857170105,0.4829864799976349,0.5164362788200378,0.516845166683197,0.5074795484542847,0.39375630021095276,0.5086944699287415,0.4396187365055084,0.5252314209938049,0.4334014356136322,0.5067736506462097,0.4252442419528961,0.40198996663093567,0.5167232155799866,0.39958062767982483,0.41166427731513977,0.4638390839099884,0.4964616000652313,0.40414106845855713,0.520795464515686,0.40834563970565796,0.39869487285614014,0.5189147591590881,0.3986380994319916,0.5189237594604492,0.43237733840942383,0.4371911883354187,0.4012084901332855,0.47696563601493835,0.43697085976600647,0.5059267282485962,0.4923878610134125,0.40268945693969727,0.39171624183654785,0.49316513538360596,0.43820616602897644,0.40624988079071045,0.38510075211524963,0.4354698657989502,0.4651638865470886,0.4085759222507477,0.4808897078037262,0.4777267277240753,0.5284744501113892,0.38536638021469116,0.4788873493671417,0.3909393846988678,0.4248219132423401,0.5212639570236206,0.5260676741600037,0.40323513746261597,0.5093480348587036,0.44970226287841797,0.37604865431785583,0.4409627914428711,0.5208083987236023,0.4370955228805542,0.42917588353157043,0.49536776542663574,0.43439921736717224,0.5533002018928528,0.41626760363578796,0.43734586238861084,0.5467656850814819,0.502439558506012,0.40056130290031433,0.42549559473991394,0.4781980514526367,0.4335339665412903,0.5333375334739685,0.43719983100891113,0.448318213224411,0.45334240794181824,0.45615726709365845,0.48874545097351074,0.5233560800552368,0.5090183615684509,0.4945167303085327,0.5258771777153015,0.39602380990982056,0.42959073185920715,0.48343661427497864,0.4463711380958557,0.5090909600257874,0.3796345591545105,0.43451249599456787,0.46861588954925537,0.49818095564842224,0.4890306293964386,0.433837890625,0.44075092673301697,0.5331631898880005,0.41153034567832947,0.5827064514160156,0.552202582359314,0.43048667907714844,0.4903378486633301,0.4483574628829956,0.43761172890663147,0.4899313449859619,0.4771812856197357,0.486987441778183,0.375784307718277,0.40418869256973267,0.3767290413379669,0.5165624618530273,0.45431602001190186,0.4324796497821808,0.4801200330257416,0.41975799202919006,0.5172474384307861,0.3877214789390564,0.4471524953842163,0.5386300683021545,0.4125390350818634,0.542964518070221,0.4673594534397125,0.4270893931388855,0.45839688181877136,0.4644899368286133,0.5263193845748901,0.49377360939979553,0.4480985999107361,0.4179607927799225,0.5181781053543091,0.43240711092948914,0.44465401768684387,0.4307907223701477,0.39705103635787964,0.45659443736076355,0.45658090710639954,0.4978334903717041,0.4821152687072754,0.4230092465877533,0.4031403660774231,0.43873393535614014,0.5651817321777344,0.4553554058074951,0.4468733072280884,0.4611000716686249,0.49734827876091003,0.4046664237976074,0.49154579639434814,0.41528406739234924,0.5357257723808289,0.43178054690361023,0.37352412939071655,0.40651801228523254,0.4701725244522095,0.4459945559501648,0.561156690120697,0.45766687393188477,0.4591556191444397,0.4800649583339691,0.5621912479400635,0.5146905183792114,0.45926499366760254,0.4121231138706207,0.43603911995887756,0.3831937313079834,0.4396374821662903,0.4042150378227234,0.5328091979026794,0.4677034318447113,0.4308346211910248,0.4396844208240509,0.47942572832107544,0.4107159674167633,0.46770668029785156,0.4162416160106659,0.41783538460731506,0.43611764907836914,0.4835273325443268,0.43903249502182007],\"type\":\"scatter3d\"}],                        {\"height\":400,\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":0},\"showlegend\":false,\"width\":600,\"scene\":{\"camera\":{\"center\":{\"x\":0,\"y\":0,\"z\":0},\"up\":{\"x\":0,\"y\":0,\"z\":1}}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a4241662-8b5b-458c-b959-3b49af5a1ff0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True  True  True ...  True  True  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh8ugKUp9WKf"
      },
      "source": [
        "# 2] Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8abAwINI9WKf"
      },
      "source": [
        "## 2.1) ResBlock + Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZfg7nQw9WKf"
      },
      "outputs": [],
      "source": [
        "class ResBlock(nn.Module):\n",
        "    \"\"\"\n",
        "        This class is used to define a Residual Block, which is one of the main component of the ResNetPointNet architecture\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_dim=64, n_points=1024, h_dim=32, out_dim=64):\n",
        "        super(ResBlock, self).__init__()\n",
        "\n",
        "        self.n_points = n_points\n",
        "\n",
        "        #> First part of the Block\n",
        "\n",
        "        self.fc1 = nn.Linear(\n",
        "            in_dim,\n",
        "            h_dim\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm1d(self.n_points)\n",
        "\n",
        "        #> Second part of the Block\n",
        "\n",
        "        self.fc2 = nn.Linear(\n",
        "            h_dim,\n",
        "            out_dim\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm1d(self.n_points)\n",
        "\n",
        "        #> Skip connection\n",
        "\n",
        "        if in_dim != out_dim:\n",
        "            # size mismatch (never happen in my case)\n",
        "            self.residual = nn.Linear(in_dim, out_dim)\n",
        "        else:\n",
        "            # same size\n",
        "            self.residual = None\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input: (b,p,in_dim) = (b,p,64)\n",
        "\n",
        "        first_part = F.relu(self.bn1(self.fc1(x))) # (b,p,64) -> (b,p,32)\n",
        "\n",
        "        second_part = self.bn2(self.fc2(first_part)) # (b,p,32) -> (b,p,64)\n",
        "\n",
        "        if self.residual is None:\n",
        "            # no size mismatch\n",
        "            res = x # (b,p,64)\n",
        "        else:\n",
        "            # transformation if there is a size mismatch in_dim != out_dim\n",
        "            res = self.residual(x) # (b,p,in_dim) -> (b,p,64)\n",
        "\n",
        "        # add residual connection\n",
        "        third_part = second_part + res # (b,p,64) -> (b,p,64)\n",
        "\n",
        "        return F.relu(third_part)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "443lgCMp9WKf"
      },
      "outputs": [],
      "source": [
        "def CoordinateNormalization(input_cloud, planeType='xz', dim=2):\n",
        "    \"\"\"\n",
        "        This Function is used to Normalize coordinates from the input point cloud.\n",
        "        After this operation the cloud will be centered at the origin and all coordinates will be inside a standard range [0,1].\n",
        "        The results will be the normalized point cloud focused only on the plane coordinate. This means that we will have only 2 coordinates for\n",
        "        our points instead of 3.\n",
        "\n",
        "        Args:\n",
        "            input_cloud : (batch_size, n_points, 3) tensor\n",
        "            planeType: (str) represent the kind of plane that we are using (xz, xy, yz)\n",
        "\n",
        "        Returns:\n",
        "            norm_cloud : (batch_size, n_points, 2) tensor\n",
        "    \"\"\"\n",
        "    # Extract coordinates according to the planeType you are using\n",
        "    if planeType == 'xz':\n",
        "        plane = input_cloud[:, :, [0,2]].to(input_cloud.device) # (b,p,3) -> (b,p,2)\n",
        "    elif planeType == 'xy':\n",
        "        plane = input_cloud[:, :, [0,1]].to(input_cloud.device) # (b,p,3) -> (b,p,2)\n",
        "    elif planeType == 'yz':\n",
        "        plane = input_cloud[:, :, [1,2]].to(input_cloud.device) # (b,p,3) -> (b,p,2)\n",
        "\n",
        "    if dim==3:\n",
        "        # this is needed to perform the reconstruction\n",
        "        # instead of a plane we need the entire space --> all x,y,z coordinates\n",
        "        plane = input_cloud.to(input_cloud.device) # (b,p,3) -> (b,p,3)\n",
        "\n",
        "    norm_cloud = (plane - plane.min())/(plane.max() - plane.min() + 10e-6)\n",
        "\n",
        "    return norm_cloud.to(input_cloud.device)\n",
        "\n",
        "\n",
        "def PlaneCoordinate2Index(input_cloud, voxel_size=1.0/64):\n",
        "    \"\"\"\n",
        "        This function is used to Obtain an Index from the Plane Coordinates of the original input cloud.\n",
        "        We need to transform Coordinates into Indices because we would like to discretize space into Voxels.\n",
        "        This index is extremely important since is used to perform Local Pooling, one of the operation of the ResNetPointNet Architecture.\n",
        "\n",
        "        Args:\n",
        "            input_cloud : (batch_size, n_points, 2) tensor\n",
        "            voxel_size : (float) represent how large the Voxels (Local Regions) are (default = 0.2)\n",
        "\n",
        "        Returns:\n",
        "            index : (batch_size, n_points, 2) tensor\n",
        "    \"\"\"\n",
        "    return torch.floor(input_cloud/voxel_size).long().to(input_cloud.device)\n",
        "\n",
        "\n",
        "def LocalPooling(norm_cloud, indices, input_cloud):\n",
        "    \"\"\"\n",
        "        Unlike the Vanilla PointNet, we perform Local Max Pooling on the output of each ResBlock and then we concatenate the result\n",
        "        with the features before the operation.\n",
        "        In order to perform this operation we have to normalize the planes coordinates and transform into indices.\n",
        "        These indices represent which voxel each point belongs to.\n",
        "\n",
        "        ResBlock ________________\n",
        "            |                    |\n",
        "            |                    |\n",
        "        LocalPool                |\n",
        "            |                    |\n",
        "            v                    |\n",
        "            +   <----------------'\n",
        "\n",
        "        Args:\n",
        "            norm_cloud: (batch_size, num_points, 2) tensor that represent the normalized input cloud related to a specific plane (xz)\n",
        "            indices: (batch_size, num_points, 2) tensor that represent the indices of the input cloud related to the Voxel\n",
        "            input_cloud: (batch_size, num_points, n_features) tensor that represent the input cloud\n",
        "\n",
        "        Returns:\n",
        "            pool_cloud: tensor of shape (batch_size, num_points, n_features)\n",
        "    \"\"\"\n",
        "    batch_size, num_points, num_features = input_cloud.shape\n",
        "    device = input_cloud.device\n",
        "    # needed to have all points together, like a single point cloud -> (batch_size * num_points, 2)\n",
        "    flat_indices = indices.view(batch_size * num_points, -1)\n",
        "\n",
        "    # needed to identify each batch -> (batch_size * num_points)\n",
        "    batch_indices = torch.arange(batch_size, device=device).view(-1, 1).expand(batch_size, num_points).reshape(-1)\n",
        "\n",
        "    # combine indices (batch_size * num_points, num_features, 3)\n",
        "    voxel_indices = torch.cat([batch_indices.unsqueeze(-1), flat_indices], dim=1)\n",
        "\n",
        "    # flatten input_cloud (batch_size * num_points, num_features)\n",
        "    input_cloud_flat = input_cloud.view(batch_size * num_points, num_features)\n",
        "\n",
        "    # maximum value in each voxel (batch_size * num_points, num_features)\n",
        "    max_pool_cloud, _ = scatter_max(input_cloud_flat, voxel_indices[:, 1], dim=0, dim_size=batch_size * num_points)\n",
        "    # back to (batch_size, num_points, n_features)\n",
        "    pool_cloud = max_pool_cloud.view(batch_size, num_points, num_features)\n",
        "\n",
        "    return pool_cloud.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk_D19aI9WKg"
      },
      "source": [
        "## 2.2) ResNetPointNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYhVqWYM9WKg"
      },
      "outputs": [],
      "source": [
        "class ResNetPointNet(nn.Module):\n",
        "    \"\"\"\n",
        "        This class is used to define the PointNet model used to form a feature embedding for each point in the Point Cloud given in input.\n",
        "        Architecture design:\n",
        "\n",
        "            @ INPUT: Tensor of shape (batch_size, num_points, 3)\n",
        "\n",
        "            > Fully Connected Layer (3, in_dim=64)\n",
        "            > 5 Residual Blocks with Local Pooling and Concatenation\n",
        "            > Fully Connected Layer (out_dim=32, out_dim=32)\n",
        "\n",
        "            @ OUTPUT: Tensor of shape (batch_size, num_points, 32)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_dim=64, n_points=1024, res_dim=32, out_dim=32, n_blocks=5):\n",
        "        super(ResNetPointNet, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(3, in_dim)\n",
        "\n",
        "        self.res = nn.ModuleList([\n",
        "            ResBlock(in_dim, n_points, res_dim, out_dim) for n_res in range(n_blocks)\n",
        "        ])\n",
        "\n",
        "        self.fc2 = nn.Linear(out_dim, out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input: (b,p,3)\n",
        "\n",
        "        # Extract Normalized coordinates and indices to perform local pooling\n",
        "\n",
        "        norm_coord = CoordinateNormalization(x) # (b,p,2)\n",
        "        coord_indices = PlaneCoordinate2Index(norm_coord) # (b,p,2)\n",
        "\n",
        "        # First FC Layer\n",
        "        fc1 = F.relu(self.fc1(x)) # (b,p,3) -> (b,p,64)\n",
        "\n",
        "        # First ResBlock\n",
        "        res = self.res[0](fc1) # (b,p,64) -> (b,p,32)\n",
        "\n",
        "        # 2-5 ResBlock\n",
        "        for res_block in self.res[1:]:\n",
        "            # Local Pooling\n",
        "            pool = LocalPooling(norm_coord, coord_indices, res) # (b,p,32)\n",
        "            # Concatenation\n",
        "            concat = torch.cat([res, pool], dim=2) # (b,p,32) | (b,p,32) -> (b,p,64)\n",
        "            # following residual block\n",
        "            res = res_block(concat) # (b,p,64) -> (b,p,32)\n",
        "\n",
        "        # Last FC Layer\n",
        "        final = F.relu(self.fc2(res)) # (b,p,32) -> (b,p,32)\n",
        "\n",
        "        #   print(f\"ResNetPointNet : input ({x.shape}) ---> output ({final.shape}) \\n\")\n",
        "\n",
        "        return final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHoALeYs9WKg"
      },
      "source": [
        "## 2.3) Plane Predictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASem9l-E9WKg"
      },
      "outputs": [],
      "source": [
        "class SimplePointNet(nn.Module):\n",
        "    \"\"\"\n",
        "        This class is used to define a simple variant of the PointNet Model, which is one of the main components of the Plane Predictor Network.\n",
        "        This Network will provide us a global context of the Input Point Clouds\n",
        "        Architecture Design:\n",
        "\n",
        "            @ INPUT: Tensor of shape (batch_size, num_points, 3) which represent the Input Point Clouds\n",
        "\n",
        "            > Fully Connected Layer (3, 64)\n",
        "\n",
        "              |> Fully Connected Layer (64, 32)\n",
        "            2*|> Global Max Pooling\n",
        "              |> Concatenation btw Pooled and unpooled features\n",
        "\n",
        "            > Fully Connected Layer (64, 32)\n",
        "            > Global Max Pooling\n",
        "\n",
        "            @ OUTPUT: Tensor of shape (batch_size, num_points, 32) which will be used by the rest of the Plane Predictor\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, batch_size, in_dim=64, n_points=1024, hid_dim=32, out_dim=64):\n",
        "        super(SimplePointNet, self).__init__()\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.n_points = n_points\n",
        "\n",
        "        self.initial_fc = nn.Linear(in_features=3, out_features=in_dim)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=in_dim, out_features=hid_dim)\n",
        "\n",
        "        self.fc2 = nn.Linear(in_features=in_dim, out_features=hid_dim)\n",
        "\n",
        "        self.final_fc = nn.Linear(in_features=in_dim, out_features=hid_dim)\n",
        "\n",
        "        self.pool = nn.AdaptiveMaxPool1d(output_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.initial_fc(x)) # (b,p,3) --> (b,p,64)\n",
        "\n",
        "        x1 = F.relu(self.fc1(x)) # (b,p,64) --> (b,p,32)\n",
        "        x1_t = x1.transpose(1,2) # (b,p,32) -> (b,32,p)\n",
        "        pool_x1 = self.pool(x1_t) # (b,32,p) -> (b,32,1)\n",
        "        exp_pool_x1 = pool_x1.transpose(1,2).expand(self.batch_size, self.n_points, 32) # (b,32,1) -> (b,1,32) -> (b,p,32)\n",
        "        concat_x1 = torch.cat([x1, exp_pool_x1], dim=2) # (b,p,32) | (b,p,32) -> (b,p,64)\n",
        "\n",
        "        x2 = F.relu(self.fc2(concat_x1)) # (b,p,64) -> (b,p,32)\n",
        "        x2_t = x2.transpose(1,2) # (b,p,32) -> (b,32,p)\n",
        "        pool_x2 = self.pool(x2_t) # (b,32,p) -> (b,32,1)\n",
        "        exp_pool_x2 = pool_x2.transpose(1,2).expand(self.batch_size, self.n_points, 32) # (b,32,1) -> (b,1,32) -> (b,p,32)\n",
        "        concat_x2 = torch.cat([x2, exp_pool_x2], dim=2) # (b,p,32) | (b,p,32) -> (b,p,64)\n",
        "\n",
        "        pre_pool_out = F.relu(self.final_fc(concat_x2)) # (b,p,64) -> (b,p,32)\n",
        "        pre_pool_out_t = pre_pool_out.transpose(1,2) # (b,p,32) -> (b,32,p)\n",
        "        out = self.pool(pre_pool_out_t) # (b,32,p) -> (b,32,1)\n",
        "\n",
        "        #   print(f\"SimplePointNet : input ({x.shape}) ---> output ({out.transpose(1,2).shape}) \\n\")\n",
        "        return out.transpose(1,2) # (b,32,1) -> (b,1,32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cWO2Alj9WKg"
      },
      "outputs": [],
      "source": [
        "class PlanePredictor(nn.Module):\n",
        "    \"\"\"\n",
        "        This class is used to define the Plane Predictor of our Architecture, which will predict the plane parameters of L dynamic planes\n",
        "        Architecture design:\n",
        "\n",
        "            @ INPUT: Tensor of shape (batch_size, num_points, 3) which represent Point Clouds\n",
        "\n",
        "            > Simple PointNet which learns the global context of the input point clouds\n",
        "            > This information is encoded into one global feature by using Max Pooling\n",
        "            > 4 Fully Connected Layers with hidden dimension = 32\n",
        "            > L Shallow Networks with hidden dimension = 3 which will give us the Predicted Plane Parameters\n",
        "            > L Fully Connected Layers with 1 layer and hidden dimension = D (same as point cloud encoder hidden dimension)\n",
        "            > Each plane-specific feature is expanded to N x D to match the output of the point cloud encoder, which will be summed together\n",
        "\n",
        "\n",
        "            @ OUTPUT: Tensor of shape (batch_size, num_points, 32) which will be processed into U-Net\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim=32, n_points=1024, n_fc=4, L=4):\n",
        "        super(PlanePredictor, self).__init__()\n",
        "\n",
        "        self.pointNet = SimplePointNet(batch_size=BATCH_SIZE, in_dim=IN_DIM_RES_PT, n_points=n_points, hid_dim=in_dim, out_dim=IN_DIM_RES_PT)\n",
        "        self.n_points = n_points\n",
        "\n",
        "        # 4 FC layers with hidden dim = 32\n",
        "\n",
        "        self.four_fc = nn.ModuleList(\n",
        "            [nn.Linear(in_dim, in_dim) for i in range(n_fc)]\n",
        "        )\n",
        "\n",
        "        # Plane parameters (L shallow networks with hidden dim = 3)\n",
        "\n",
        "        self.first_shallow = nn.Linear(in_dim, 3)\n",
        "        self.shallows = nn.ModuleList(\n",
        "            [nn.Linear(3, 3) for i in range(L-1)]\n",
        "        )\n",
        "\n",
        "        # L FC layers with hidden dim = 32\n",
        "\n",
        "        self.first_fc = nn.Linear(3, in_dim)\n",
        "        self.L_fc = nn.ModuleList(\n",
        "            [nn.Linear(in_dim, in_dim) for i in range(L-1)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        flc = self.pointNet(x) # (b,p,3) -> (b,1,32)\n",
        "\n",
        "        # 4 FC layers with hidden dim = 32\n",
        "\n",
        "        for fc in self.four_fc:\n",
        "            flc = F.relu(fc(flc))  # (b,1,32) -> (b,1,32)\n",
        "\n",
        "        # Plane parameters ( L Shallow Networks )\n",
        "\n",
        "        first_sh = F.relu(self.first_shallow(flc)) # (b,1,32) -> (b,1,3)\n",
        "        shal = first_sh\n",
        "        for s in self.shallows:\n",
        "            shal = F.relu(s(shal)) # (b,1,3) -> (b,1,3)\n",
        "\n",
        "        # L FC networks dim = 32\n",
        "\n",
        "        first_fc_L = F.relu(self.first_fc(shal)) # (b,1,3) -> (b,1,32)\n",
        "        L_fully = first_fc_L\n",
        "        for fc in self.L_fc:\n",
        "            L_fully = F.relu(fc(L_fully))  # (b,1,32) -> (b,1,32)\n",
        "\n",
        "        # Expansion\n",
        "\n",
        "        out = L_fully.expand(x.shape[0], self.n_points, first_fc_L.shape[-1]) # (b,1,32) -> (b,p,32)\n",
        "\n",
        "        #   print(f\"PlanePredictor : input ({x.shape}) ---> output ({out.shape}) \\n\")\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbmuG1FR9WKh"
      },
      "outputs": [],
      "source": [
        "def FeatureProjection(input_cloud, features, resolution=64):\n",
        "    \"\"\"\n",
        "        This function is used to extract the Feauture Projections from the output of the Plane Predictor summed to the output of the ResNetPointNet\n",
        "        Args:\n",
        "            input_cloud: (batch_size, num_points, 3) tensor that represent the input cloud\n",
        "            features: (batch_size), num_points, n_features=32) tensor that represent the features extracted by the Plane Predictor summed to the ones of ResNetPointNet\n",
        "\n",
        "        Returns:\n",
        "            proj_features: (batch_size, num_points, ) tensor that represent the projected cloud\n",
        "    \"\"\"\n",
        "    norm_cloud = CoordinateNormalization(input_cloud) # (b,p,3) -> (b,p,2)\n",
        "    indices = PlaneCoordinate2Index(norm_cloud) # (b,p,2) -> (b,p,2)\n",
        "    flatten_indices = indices[:, :, 0] + indices[:, :, 1]*resolution # (b,p,2) -> (b,p)\n",
        "\n",
        "    proj_features = torch.zeros(input_cloud.shape[0], features.shape[2], resolution**2) # (b,32,res^2) = (b,32,4096)\n",
        "\n",
        "    proj_features = scatter_mean(features.transpose(2,1), flatten_indices.unsqueeze(1), dim=2, out=proj_features)\n",
        "\n",
        "    #   print(f\"Feature Projection : input ({input_cloud.shape}) ---> output ({proj_features.reshape(input_cloud.shape[0], features.shape[2], resolution, resolution).shape}) \\n\")\n",
        "\n",
        "    return proj_features.reshape(input_cloud.shape[0], features.shape[2], resolution, resolution) # (b,32,res,res) = (b,32,64,64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BEqvWJV9WKh"
      },
      "source": [
        "## 2.4) UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVGhQD969WKh"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    \"\"\"\n",
        "        This class is used to define the UNet of our Architecture, which is the final part of our Encoder.\n",
        "        Architecture design:\n",
        "\n",
        "        @ INPUT: Tensor of shape (batch_size, 32, 64, 64)\n",
        "            # Encoder:\n",
        "\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "\n",
        "                > MaxPool2D\n",
        "\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "\n",
        "                > MaxPool2D\n",
        "\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "\n",
        "                > MaxPool2D\n",
        "\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "\n",
        "            # BottleNeck:\n",
        "\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "\n",
        "            # Decoder:\n",
        "\n",
        "                > UpConv2D\n",
        "                > Concat\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "\n",
        "                > UpConv2D\n",
        "                > Concat\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "\n",
        "                > UpConv2D\n",
        "                > Concat\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "\n",
        "                > UpConv2D\n",
        "                > Concat\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "                > Conv2D\n",
        "                > BatchNorm\n",
        "                > ReLU\n",
        "\n",
        "                > Conv2D\n",
        "\n",
        "        @ OUTPUT: Tensor of shape (batch_size, num_points, 32)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim=32, out_dim=32, features_dim=64, n_points=1024):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(\n",
        "            kernel_size=2,\n",
        "            stride=2\n",
        "        )\n",
        "\n",
        "        # Encoder\n",
        "\n",
        "        ## Block 1\n",
        "\n",
        "        self.e_1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_dim,\n",
        "                out_channels=features_dim,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim,\n",
        "                out_channels=features_dim,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.p_1 = nn.MaxPool2d(\n",
        "            kernel_size=2,\n",
        "            stride=2\n",
        "        )\n",
        "\n",
        "        ## Block 2\n",
        "\n",
        "        self.e_2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim,\n",
        "                out_channels=features_dim*2,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim*2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim*2,\n",
        "                out_channels=features_dim*2,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim*2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.p_2 = nn.MaxPool2d(\n",
        "            kernel_size=2,\n",
        "            stride=2\n",
        "        )\n",
        "\n",
        "        ## Block 3\n",
        "\n",
        "        self.e_3 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim*2,\n",
        "                out_channels=features_dim*4,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim*4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim*4,\n",
        "                out_channels=features_dim*4,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim*4),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.p_3 = nn.MaxPool2d(\n",
        "            kernel_size=2,\n",
        "            stride=2\n",
        "        )\n",
        "\n",
        "        ## Block 4\n",
        "\n",
        "        self.e_4 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim*4,\n",
        "                out_channels=features_dim*8,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim*8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim*8,\n",
        "                out_channels=features_dim*8,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim*8),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.p_4 = nn.MaxPool2d(\n",
        "            kernel_size=2,\n",
        "            stride=2\n",
        "        )\n",
        "\n",
        "        # Bottleneck\n",
        "\n",
        "        self.b = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim*8,\n",
        "                out_channels=features_dim*16,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim*16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim*16,\n",
        "                out_channels=features_dim*16,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim*16),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "\n",
        "        ## Block 1\n",
        "\n",
        "        self.d_upconv1 = nn.ConvTranspose2d(\n",
        "            in_channels=features_dim*16,\n",
        "            out_channels=features_dim*8,\n",
        "            kernel_size=2,\n",
        "            stride=2)\n",
        "\n",
        "        self.d_1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim*16,\n",
        "                out_channels=features_dim*8,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim*8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim*8,\n",
        "                out_channels=features_dim*8,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim*8),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        ## Block 2\n",
        "\n",
        "        self.d_upconv2 = nn.ConvTranspose2d(\n",
        "            in_channels=features_dim*8,\n",
        "            out_channels=features_dim*4,\n",
        "            kernel_size=2,\n",
        "            stride=2)\n",
        "\n",
        "        self.d_2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim*8,\n",
        "                out_channels=features_dim*4,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim*4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim*4,\n",
        "                out_channels=features_dim*4,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim*4),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        ## Block 3\n",
        "\n",
        "        self.d_upconv3 = nn.ConvTranspose2d(\n",
        "            in_channels=features_dim*4,\n",
        "            out_channels=features_dim*2,\n",
        "            kernel_size=2,\n",
        "            stride=2)\n",
        "\n",
        "        self.d_3 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim*4,\n",
        "                out_channels=features_dim*2,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim*2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim*2,\n",
        "                out_channels=features_dim*2,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim*2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        ## Block 4\n",
        "\n",
        "        self.d_upconv4 = nn.ConvTranspose2d(\n",
        "            in_channels=features_dim*2,\n",
        "            out_channels=features_dim,\n",
        "            kernel_size=2,\n",
        "            stride=2)\n",
        "\n",
        "        self.d_4 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim*2,\n",
        "                out_channels=features_dim,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=features_dim,\n",
        "                out_channels=features_dim,\n",
        "                kernel_size=3,\n",
        "                padding=1\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=features_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.final = nn.Conv2d(\n",
        "                in_channels=features_dim,\n",
        "                out_channels=out_dim,\n",
        "                kernel_size=1\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        enc1 = self.e_1(x)\n",
        "        #print(f\"Encoder block 1 : input ({x.shape}) ---> output ({enc1.shape})\")\n",
        "        enc2 = self.e_2(self.p_1(enc1))\n",
        "        #print(f\"Encoder block 2 : input ({self.p_1(enc1).shape}) ---> output ({enc2.shape})\")\n",
        "        enc3 = self.e_3(self.p_2(enc2))\n",
        "        #print(f\"Encoder block 3 : input ({self.p_2(enc2).shape}) ---> output ({enc3.shape})\")\n",
        "        enc4 = self.e_4(self.p_3(enc3))\n",
        "        #print(f\"Encoder block 4 : input ({self.p_3(enc3).shape}) ---> output ({enc4.shape})\")\n",
        "\n",
        "        bottle = self.b(self.p_4(enc4))\n",
        "        #print(f\"BottleNeck : input ({self.p_4(enc4).shape}) ---> output ({bottle.shape})\")\n",
        "\n",
        "        dec1 = self.d_upconv1(bottle)\n",
        "        dec1 = torch.cat((dec1, enc4), dim=1)\n",
        "        dec1 = self.d_1(dec1)\n",
        "        #print(f\"Decoder block 1 : input ({bottle.shape}) ---> output ({dec1.shape})\")\n",
        "        dec2 = self.d_upconv2(dec1)\n",
        "        dec2 = torch.cat((dec2, enc3), dim=1)\n",
        "        dec2 = self.d_2(dec2)\n",
        "        #print(f\"Decoder block 2 : input ({dec1.shape}) ---> output ({dec2.shape})\")\n",
        "        dec3 = self.d_upconv3(dec2)\n",
        "        dec3 = torch.cat((dec3, enc2), dim=1)\n",
        "        dec3 = self.d_3(dec3)\n",
        "        #print(f\"Decoder block 3 : input ({dec2.shape}) ---> output ({dec3.shape})\")\n",
        "        dec4 = self.d_upconv4(dec3)\n",
        "        dec4 = torch.cat((dec4, enc1), dim=1)\n",
        "        dec4 = self.d_4(dec4)\n",
        "        #print(f\"Decoder block 4 : input ({dec3.shape}) ---> output ({dec4.shape})\")\n",
        "        out = self.final(dec4)\n",
        "        #print(f\"Final : input ({dec4.shape}) ---> output ({out.shape})\")\n",
        "\n",
        "\n",
        "        #   print(f\"UNet : input ({x.shape}) ---> output ({out.shape}) \\n\")\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fME3ek-b9WKh"
      },
      "source": [
        "## 2.5) Complete Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEnfYEQZ9WKh"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, in_dim=64, out_dim=32, n_points=1024, n_blocks=5, num_planes=4, num_fc=4):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.resnet_pointnet = ResNetPointNet(in_dim=in_dim, n_points=n_points, out_dim=out_dim, n_blocks=n_blocks)\n",
        "        self.plane_predictor = PlanePredictor(in_dim=out_dim, n_points=n_points, n_fc=num_fc, L=num_planes)\n",
        "        self.UNet = UNet(in_dim=out_dim, out_dim=out_dim, features_dim=in_dim, n_points=n_points)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        resnet = self.resnet_pointnet(x)\n",
        "        plane_pred = self.plane_predictor(x)\n",
        "        # here we need to perform features projection\n",
        "        features_proj = FeatureProjection(x, resnet + plane_pred)\n",
        "        out = self.UNet(features_proj)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xfwdl8S9WKi"
      },
      "source": [
        "# 3] Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3Cu6WzB9WKi"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "        This class is used to define the Decoder Network. The architecture is composed by 5 ResNet blocks with hidden dimension 32 followed by a small\n",
        "        Fully Connected netowrk that returns the Occupancy prediction.\n",
        "        Given the features vector in input, we have to perform Bilinear Interpolation before the ResNet blocks.\n",
        "        Architecture design:\n",
        "\n",
        "            @ INPUT:\n",
        "\n",
        "                > Tensor of shape [input_cloud] (batch_size, n_points=1024, 3)\n",
        "                > Tensor of shape [features vector] (batch_size, features=32, resolution=64, resolution=64)\n",
        "\n",
        "\n",
        "            @ OUTPUT:\n",
        "\n",
        "                > Tensor of shape [occupancy prediction] (batch_size, n_points=1024, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_dim=32, n_points=1024, n_blocks=5):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.res_blocks = nn.ModuleList(\n",
        "            [ResBlock(in_dim, n_points, in_dim, in_dim) for i in range(n_blocks)]\n",
        "        )\n",
        "        self.occupancy_pred = nn.Sequential(\n",
        "            nn.Linear(in_dim, in_dim//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_dim//2, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, input, input_features):\n",
        "        x = input\n",
        "\n",
        "        # Normalize your Input Cloud to 2D and Apply Bilinear Interpolation\n",
        "\n",
        "        norm_cloud = CoordinateNormalization(input)\n",
        "\n",
        "        # print(f\"norm_cloud : ({norm_cloud.shape}), unsqueeze : ({norm_cloud.unsqueeze(2).shape})\")\n",
        "\n",
        "        interpolated_features = F.grid_sample(input_features, norm_cloud.unsqueeze(2), mode='bilinear', align_corners=True)\n",
        "\n",
        "        # print(f\"interpolated_features : ({interpolated_features.shape}), squeeze : ({interpolated_features.squeeze(-1).shape})\")\n",
        "\n",
        "        x = interpolated_features.squeeze(-1).transpose(2,1)\n",
        "\n",
        "        for res_block in self.res_blocks:\n",
        "            x = res_block(x)\n",
        "\n",
        "        occupancy = self.occupancy_pred(x)\n",
        "        # print(f\"occupancy : ({occupancy.shape})\")\n",
        "\n",
        "        #   print(f\"Decoder : ({input_features.shape}) --> ({occupancy.shape}) \\n\")\n",
        "\n",
        "        return occupancy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbexQquN9WKi"
      },
      "source": [
        "# 4] Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh9zVxRg_PxY"
      },
      "source": [
        "<font color=\"orange\"> Chamster Distance: </font> $\n",
        "CD(A, B) = \\frac{1}{|A|} \\sum_{a \\in A} \\min_{b \\in B} \\|a - b\\|_2^2 + \\frac{1}{|B|} \\sum_{b \\in B} \\min_{a \\in A} \\|b - a\\|_2^2\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcU830ok9WKj"
      },
      "outputs": [],
      "source": [
        "# Chamster Distance\n",
        "def ChamsterDistance(input_cloud, pred_cloud):\n",
        "    \"\"\"\n",
        "        This function is used to compute the Chamster Distance between the input cloud and the predicted cloud.\n",
        "        This metrics is composed by sum of the distances from each point in input_cloud to its nearest neighbor in pred_cloud\n",
        "        plus the distances from each point in pred_cloud to its nearest neighbor in input_cloud.\n",
        "        We would like to MINIMIZE this metric.\n",
        "\n",
        "        @ INPUT :\n",
        "            > tensor of shape (batch_size, num_points, 3)\n",
        "            > tensor of shape (batch_size, num_points, 3)\n",
        "\n",
        "        @ OUTPUT :\n",
        "            > tensor of shape (batch_size, num_points, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    A = input_cloud.detach().cpu()\n",
        "    B = pred_cloud.detach().cpu()\n",
        "\n",
        "    dists_A_to_B = torch.cdist(A, B, p=2)\n",
        "    dists_B_to_A = torch.cdist(B, A, p=2)\n",
        "\n",
        "    print(f\"dists_A_to_B : ({dists_A_to_B.shape})\")\n",
        "    print(f\"dists_B_to_A : ({dists_B_to_A.shape})\")\n",
        "\n",
        "    min_A_to_B = torch.min(dists_A_to_B, dim=1)[0]\n",
        "    min_B_to_A = torch.min(dists_B_to_A, dim=1)[0]\n",
        "\n",
        "    print(f\"min_A_to_B : ({min_A_to_B.shape})\")\n",
        "    print(f\"min_B_to_A : ({min_B_to_A.shape})\")\n",
        "\n",
        "    CD = torch.mean(min_A_to_B) + torch.mean(min_B_to_A)\n",
        "\n",
        "    print(f\"Chamster Distance : ({CD.shape}) \\n\")\n",
        "\n",
        "    return CD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb7uqm2c_Wbf"
      },
      "source": [
        "<font color=\"orange\"> Volumetric IOU: </font> $ IoU(A', B') = \\frac{|A' \\cap B'|}{|A' \\cup B'|}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMwdO44rEyJl"
      },
      "outputs": [],
      "source": [
        "# Intersection Over Union\n",
        "def VolumetricIOU(real_cloud, pred_cloud):\n",
        "    \"\"\"\n",
        "        This function is used to compute the Intersection Over Union between two volumes\n",
        "\n",
        "        @ INPUT :\n",
        "            > tensor of shape (batch_size, ...) (actually binary voxel grid)\n",
        "            > tensor of shape (batch_size, ...) (actually binary voxel grid)\n",
        "\n",
        "        @ OUTPUT :\n",
        "            > float\n",
        "    \"\"\"\n",
        "    real_cloud = np.array(real_cloud, dtype=np.bool)\n",
        "    pred_cloud = np.array(pred_cloud, dtype=np.bool)\n",
        "\n",
        "    return np.sum(real_cloud & pred_cloud) / np.sum(pred_cloud) + np.sum(real_cloud)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"orange\"> F-Score: </font>"
      ],
      "metadata": {
        "id": "lyvI3CLJJ3Re"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQEisF9oIkWx"
      },
      "outputs": [],
      "source": [
        "# F-score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"orange\"> Normal Consistency: </font>"
      ],
      "metadata": {
        "id": "6cBjgw_UJ5_R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVAClDUMIl0T"
      },
      "outputs": [],
      "source": [
        "# Normal Consistency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIpxjGH19WKj"
      },
      "source": [
        "# 5] Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4zji7u90ISp"
      },
      "outputs": [],
      "source": [
        "def OccupancyGroundTruth(sampled_points, registration_points, threshold=0.05):\n",
        "    \"\"\"\n",
        "        This function is used to obtain the occupancy ground truth from the registration of the input cloud.\n",
        "        This is crucial since it will be the quantity compared to the occupancy prediction.\n",
        "        The dataset provide the registration of the input cloud, which is the set of point on the surface of each figure.\n",
        "\n",
        "        @ INPUT :\n",
        "            > sampled_points: tensor of shape (batch_size, num_points=1024, 3)\n",
        "            > registration_points: tensor of shape (batch_size, num_points_reg , 3)\n",
        "            > threshold: float, default=0.05\n",
        "\n",
        "        @ OUTPUT :\n",
        "            > tensor of shape (batch_size, num_points, 1)\n",
        "    \"\"\"\n",
        "    # compute the distance between each of the sampled points and all the registration's points\n",
        "    dis = sampled_points[:, :, None, :] - registration_points[:, None, :, :]\n",
        "    distances = torch.norm(dis, dim=-1)\n",
        "    # find the minimum distances aka the distance between each point and its nearest neighbor\n",
        "    min_distances, _ = torch.min(distances, dim=2)\n",
        "    return (min_distances < threshold).float().unsqueeze(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBGZGh8yBHMp"
      },
      "outputs": [],
      "source": [
        "class CompleteArchitecture(nn.Module):\n",
        "\n",
        "    def __init__(self, in_dim=64, out_dim=32, n_points=1024, n_blocks=5, num_planes=4, num_fc=4):\n",
        "        super(CompleteArchitecture, self).__init__()\n",
        "        self.encoder = Encoder(in_dim, out_dim, n_points, n_blocks, num_planes, num_fc)\n",
        "        self.decoder = Decoder(out_dim, n_points, n_blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_enc = self.encoder(x)\n",
        "        out_dec = self.decoder(x, out_enc)\n",
        "        return out_dec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heghvvVw9WKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a43b1c-2bc0-4b1c-ac55-a9d54bf420d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], Train Loss: 0.5437, Val Loss: 0.5872\n",
            "Epoch [2/25], Train Loss: 0.3200, Val Loss: 0.4081\n",
            "Epoch [3/25], Train Loss: 0.2150, Val Loss: 0.2421\n",
            "Epoch [4/25], Train Loss: 0.1468, Val Loss: 0.1307\n",
            "Epoch [5/25], Train Loss: 0.0986, Val Loss: 0.0489\n",
            "Epoch [6/25], Train Loss: 0.0652, Val Loss: 0.0502\n",
            "Epoch [7/25], Train Loss: 0.0451, Val Loss: 0.0298\n",
            "Epoch [8/25], Train Loss: 0.0299, Val Loss: 0.0244\n",
            "Epoch [9/25], Train Loss: 0.0217, Val Loss: 0.0205\n",
            "Epoch [10/25], Train Loss: 0.0155, Val Loss: 0.0192\n",
            "Epoch [11/25], Train Loss: 0.0123, Val Loss: 0.0108\n",
            "Epoch [12/25], Train Loss: 0.0096, Val Loss: 0.0105\n",
            "Epoch [13/25], Train Loss: 0.0078, Val Loss: 0.0103\n",
            "Epoch [14/25], Train Loss: 0.0062, Val Loss: 0.0078\n",
            "Epoch [15/25], Train Loss: 0.0056, Val Loss: 0.0059\n",
            "Epoch [16/25], Train Loss: 0.0047, Val Loss: 0.0061\n",
            "Epoch [17/25], Train Loss: 0.0040, Val Loss: 0.0062\n",
            "Epoch [18/25], Train Loss: 0.0034, Val Loss: 0.0041\n",
            "Epoch [19/25], Train Loss: 0.0032, Val Loss: 0.0050\n",
            "Epoch [20/25], Train Loss: 0.0027, Val Loss: 0.0038\n",
            "Epoch [21/25], Train Loss: 0.0025, Val Loss: 0.0033\n",
            "Epoch [22/25], Train Loss: 0.0023, Val Loss: 0.0030\n",
            "Epoch [23/25], Train Loss: 0.0020, Val Loss: 0.0028\n",
            "Epoch [24/25], Train Loss: 0.0019, Val Loss: 0.0029\n",
            "Epoch [25/25], Train Loss: 0.0018, Val Loss: 0.0031\n"
          ]
        }
      ],
      "source": [
        "completeModel = CompleteArchitecture(in_dim=IN_DIM_RES_PT, out_dim=FEATURES_DIM, n_points=SAMPLING_SIZE, n_blocks=NUM_BLOCKS, num_planes=NUM_PLANES, num_fc=NUM_FC)\n",
        "completeModel = completeModel.to(device)\n",
        "BCE = nn.BCELoss() # later change this and use the version with logits (remember to delete sigmoid in the occupancy pred network)\n",
        "optimizer = torch.optim.Adam(completeModel.parameters(), lr=1e-4) # currently using the same from the paper\n",
        "num_epochs = 25\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    completeModel.train()\n",
        "\n",
        "    train_loss = 0.0\n",
        "\n",
        "    train_loss_cnt = []\n",
        "    val_loss_cnt = []\n",
        "\n",
        "    # add other metrics container (IOU, chamfer, ...)\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        sampled_cloud, ground_truth = batch[0].to(device), batch[1].to(device)\n",
        "        # use the gpu\n",
        "        occupancy_pred = completeModel(sampled_cloud)\n",
        "        # calculate the loss between the occupancy prediction and the real occupancy\n",
        "        real_occupancy =  OccupancyGroundTruth(sampled_cloud, ground_truth)\n",
        "\n",
        "        loss = BCE(occupancy_pred, real_occupancy)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_loss_cnt.append(avg_train_loss)\n",
        "\n",
        "\n",
        "    completeModel.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            sampled_cloud, ground_truth = batch[0].to(device), batch[1].to(device)\n",
        "            # use the gpu\n",
        "            occupancy_pred = completeModel(sampled_cloud)\n",
        "            real_occupancy = OccupancyGroundTruth(sampled_cloud, ground_truth)\n",
        "            loss = BCE(occupancy_pred, real_occupancy)\n",
        "            val_loss += loss.item()\n",
        "            # perform the reconstruction\n",
        "            # meshes = Reconstruction(occupancy_pred, sampled_cloud)\n",
        "            # compute other metrics\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_loss_cnt.append(avg_val_loss)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "    # save the model if it's better than the last one\n",
        "\n",
        "    \"\"\"\n",
        "    torch.save(\n",
        "        {\n",
        "        'model_state_dict': completeModel.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        },\n",
        "        'model.pt'\n",
        "    )\n",
        "    \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss_cnt, label='Train')\n",
        "plt.plot(val_loss_cnt, label='Val')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('losses.png')"
      ],
      "metadata": {
        "id": "ypdSm5bEsFIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u0r2Gpj9WKj"
      },
      "source": [
        "# 6] Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first discretize the volumetric space at an initial resolution and evaluate the occupancy network fθ (p, x) for all p in this grid.\n",
        "We mark all grid points p as <font color=\"orange\"> occupied </font> for which fθ(p,x) is bigger or equal to some threshold τ. Next, we mark all voxels as <font color=\"olive\"> active </font> for which **at least\n",
        "two adjacent grid points** have differing occupancy predictions. These are the voxels which would intersect the mesh with the marching cubes algorithm\n",
        "at the current resolution. We subdivide **all active voxels into**<font color=\"orange\"> 8 </font>**subvoxels** and evaluate all new grid points which are introduced to the occupancy grid through\n",
        "this subdivision. We repeat these steps until the desired final resolution is reached.\n",
        "At this final resolution, we apply the Marching Cubes algorithm to extract an approximate isosurface :\n",
        "{p ∈ R3 | fθ(p,x) = τ}.\n",
        "Our algorithm converges to the correct mesh if the occupancy grid at the initial resolution contains points from every connected component of both the\n",
        "interior and the exterior of the mesh. It is hence important to take an initial resolution which is high enough to satisfy this condition.\n",
        "In practice, we found that an initial resolution of $32^3$ was sufficient in almost all cases.\n",
        "The initial mesh extracted by the Marching Cubes algorithm can be further refined. In a first step, we simplify the mesh using the\n",
        "Fast-Quadric-Mesh-Simplification algorithm. Finally, we refine the output mesh using first and second order (i.e., gradient) information.\n",
        "Towards this goal, we sample random points pk from each face of the output mesh and minimize the loss."
      ],
      "metadata": {
        "id": "LMacvgWc2qzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotMesh(vertices, faces):\n",
        "    \"\"\"\n",
        "    This function is used to plot a 3D Mesh.\n",
        "\n",
        "    Args:\n",
        "        vertices (np.array): Array of mesh vertices.\n",
        "        faces (np.array): Array of mesh faces (triangles).\n",
        "\n",
        "    Returns:\n",
        "        Plot\n",
        "    \"\"\"\n",
        "    i = []\n",
        "    j = []\n",
        "    k = []\n",
        "    for face in faces:\n",
        "        i.append(face[0])\n",
        "        j.append(face[1])\n",
        "        k.append(face[2])\n",
        "    fig = go.Figure(data=[go.Mesh3d(\n",
        "        x=vertices[:, 0],\n",
        "        y=vertices[:, 1],\n",
        "        z=vertices[:, 2],\n",
        "        i=i,\n",
        "        j=j,\n",
        "        k=k,\n",
        "        opacity=0.8,\n",
        "        color='lightblue'\n",
        "    )])\n",
        "    fig.update_layout(\n",
        "        scene=dict(\n",
        "            xaxis=dict(visible=True),\n",
        "            yaxis=dict(visible=True),\n",
        "            zaxis=dict(visible=True),\n",
        "        ),\n",
        "        margin=dict(l=0, r=0, b=0, t=0)\n",
        "    )\n",
        "\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "6y1hIAvXePXg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9_0FERiAhMW8",
        "GFBi0FgT9WKe",
        "Rh8ugKUp9WKf",
        "8abAwINI9WKf",
        "QHoALeYs9WKg",
        "3BEqvWJV9WKh",
        "fME3ek-b9WKh",
        "_Xfwdl8S9WKi",
        "FbexQquN9WKi"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}